{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python38264bittranslationdetectorhiqwxbpzvenv4b85a69a239941bfb36f97ba6eeac7ae",
      "display_name": "Python 3.8.2 64-bit ('TranslationDetector-hIqwxbpz': venv)"
    },
    "colab": {
      "name": "sandbox.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pablogadhi/TranslationDetector/blob/master/sandbox.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uG8TzpWkX1nO",
        "colab_type": "code",
        "outputId": "c5e76895-3393-481b-c1dd-d97677adea07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!git clone https://github.com/pablogadhi/TranslationDetector\n",
        "!python -m spacy download en\n",
        "!python -m spacy download es\n",
        "%cd TranslationDetector\n",
        "!pip install --upgrade torch torchtext"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'TranslationDetector'...\n",
            "remote: Enumerating objects: 96, done.\u001b[K\n",
            "remote: Counting objects: 100% (96/96), done.\u001b[K\n",
            "remote: Compressing objects: 100% (67/67), done.\u001b[K\n",
            "remote: Total 96 (delta 52), reused 63 (delta 28), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (96/96), done.\n",
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (47.1.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.9)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n",
            "Collecting es_core_news_sm==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-2.2.5/es_core_news_sm-2.2.5.tar.gz (16.2MB)\n",
            "\u001b[K     |████████████████████████████████| 16.2MB 541kB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from es_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (47.1.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (0.6.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->es_core_news_sm==2.2.5) (1.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->es_core_news_sm==2.2.5) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->es_core_news_sm==2.2.5) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->es_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->es_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->es_core_news_sm==2.2.5) (3.1.0)\n",
            "Building wheels for collected packages: es-core-news-sm\n",
            "  Building wheel for es-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for es-core-news-sm: filename=es_core_news_sm-2.2.5-cp36-none-any.whl size=16172936 sha256=f368c612122485be7e93b5df491f6c67d70aac3b685bb0b33ce2faed6b504f41\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-h8ml_4ub/wheels/05/4f/66/9d0c806f86de08e8645d67996798c49e1512f9c3a250d74242\n",
            "Successfully built es-core-news-sm\n",
            "Installing collected packages: es-core-news-sm\n",
            "Successfully installed es-core-news-sm-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('es_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/es_core_news_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/es\n",
            "You can now load the model via spacy.load('es')\n",
            "/content/TranslationDetector\n",
            "Requirement already up-to-date: torch in /usr/local/lib/python3.6/dist-packages (1.5.0+cu101)\n",
            "Collecting torchtext\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/17/e7c588245aece7aa93f360894179374830daf60d7ed0bbb59332de3b3b61/torchtext-0.6.0-py3-none-any.whl (64kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 6.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from torchtext) (1.12.0)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 13.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from torchtext) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2020.4.5.1)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2.9)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (1.24.3)\n",
            "Installing collected packages: sentencepiece, torchtext\n",
            "  Found existing installation: torchtext 0.3.1\n",
            "    Uninstalling torchtext-0.3.1:\n",
            "      Successfully uninstalled torchtext-0.3.1\n",
            "Successfully installed sentencepiece-0.1.91 torchtext-0.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0FtCASL4cnB",
        "colab_type": "code",
        "outputId": "94335dec-53b5-441f-9aaa-f5fad01cb0c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PE1l5dNzZ_64",
        "colab_type": "code",
        "outputId": "285c0f93-7e86-456f-965c-d13b7710d40d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!git pull"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-xIrWVKXwyc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import torch\n",
        "from translation.train import train_model, run_epoch\n",
        "from translation.data_loader import load_data, make_iters, make_batch\n",
        "from translation.transformer import Transformer\n",
        "from translation.utils import LabelSmoothing, LossCompute, DynamicOptimizer\n",
        "from translation.translate import translate_dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vi40z2LrXwym",
        "colab_type": "code",
        "outputId": "f12da5e1-c35a-4301-e17c-66a117840d89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CLkwuwc5VBQ",
        "colab_type": "code",
        "outputId": "272d87e8-20b4-476f-d067-d15ded10bb34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Jun 12 00:47:30 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P8    10W /  70W |     10MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUn26OeiXwyw",
        "colab_type": "text"
      },
      "source": [
        "### Load data and create the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtOFq2VT4tyK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_DIR='/content/drive/My Drive/NLP/data/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ixf7Ff4_Xwyx",
        "colab_type": "code",
        "outputId": "d08502e9-8658-4faf-d3cd-7f7f0376fc5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "SRC, TGT, train, valid, test = load_data(\n",
        "        DATA_DIR + \"en-es-0_\", \"en.txt\", \"es.txt\", DATA_DIR + \"SRC_Field.pt\", DATA_DIR + \"TGT_Field.pt\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "Data loaded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_c_45HZAXwy4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_itr, valid_itr, test_itr = make_iters(\n",
        "        train, valid, test, device, batch_size=4000)\n",
        "model = Transformer(len(SRC.vocab), len(TGT.vocab)).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbNzEw9xXwzJ",
        "colab_type": "code",
        "outputId": "43f50144-9af4-4dc0-aebc-93ae4cedfb20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(SRC.vocab.itos)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLQ7ImaaXwzN",
        "colab_type": "text"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SF1CDRaYXwzO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_model(model, train_itr, valid_itr, SRC, TGT, device, 10, save_at=1, checkpoint_f=DATA_DIR + \"checkpoint.pt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LEmLlwF-wFL",
        "colab_type": "text"
      },
      "source": [
        "### Test saved models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJaGPSId_Zza",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "d4184649-abbd-4c74-8c9a-ba4279284c9e"
      },
      "source": [
        "SRC, TGT, train_en, val_en, test_en = load_data(\n",
        "        DATA_DIR + \"en-es-0_\", \"en.txt\", \"es.txt\", DATA_DIR + \"SRC_Field.pt\", DATA_DIR + \"TGT_Field.pt\")\n",
        "\n",
        "en_model_data = torch.load(DATA_DIR +\"en-es_checkpoint_2.pt\")\n",
        "en_model = Transformer(len(SRC.vocab), len(TGT.vocab)).to(device)\n",
        "en_model.load_state_dict(en_model_data)\n",
        "\n",
        "train_itr_en, valid_itr_en, test_itr_en = make_iters(\n",
        "        train_en, val_en, test_en, device, batch_size=4000)\n",
        "\n",
        "_, _, train_es, val_es, test_es = load_data(\n",
        "        DATA_DIR + \"en-es-0_\", \"es.txt\", \"en.txt\", DATA_DIR + \"TGT_Field.pt\", DATA_DIR + \"SRC_Field.pt\")\n",
        "\n",
        "es_model_data = torch.load(DATA_DIR +\"es-en_checkpoint_2.pt\")\n",
        "es_model = Transformer(len(TGT.vocab), len(SRC.vocab)).to(device)\n",
        "es_model.load_state_dict(es_model_data)\n",
        "\n",
        "train_itr_es, valid_itr_es, test_itr_es = make_iters(\n",
        "        train_es, val_es, test_es, device, batch_size=4000)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "Data loaded!\n",
            "Loading data...\n",
            "Data loaded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKqgYxfcIgmu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "70989d01-3be3-4c34-db7d-b4407dba4739"
      },
      "source": [
        "test_en"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torchtext.data.dataset.Dataset at 0x7f98341d9160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2v5mrahKAVmu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "e87f3c23-e34c-4d26-83e2-08844f8fff53"
      },
      "source": [
        "src_pad = SRC.vocab.stoi['<pad>']\n",
        "tgt_pad = TGT.vocab.stoi['<pad>']\n",
        "criterion = LabelSmoothing(\n",
        "    size=len(TGT.vocab), padding_idx=tgt_pad, smoothing=0.1).to(device)\n",
        "optimizer = DynamicOptimizer(en_model.core.d_model, 1, 2000,\n",
        "                              torch.optim.Adam(en_model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))\n",
        "compute_loss = LossCompute(en_model.generator, criterion, optimizer)\n",
        "\n",
        "en_model.eval()\n",
        "en_valid_loss = run_epoch(\n",
        "    en_model, (make_batch(b, src_pad, tgt_pad, device)\n",
        "            for b in test_itr_en),\n",
        "    LossCompute(en_model.generator, criterion, None), 100, device)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
            "\tnonzero(Tensor input, *, Tensor out)\n",
            "Consider using one of the following signatures instead:\n",
            "\tnonzero(Tensor input, *, bool as_tuple)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step   100 : 582.07 ms/batch | loss  3.22 | perplexity 25.03\n",
            "Step   200 : 549.25 ms/batch | loss  3.46 | perplexity 31.87\n",
            "Step   300 : 564.84 ms/batch | loss  3.17 | perplexity 23.81\n",
            "Step   400 : 559.92 ms/batch | loss  3.31 | perplexity 27.42\n",
            "Step   500 : 559.09 ms/batch | loss  2.80 | perplexity 16.52\n",
            "Step   600 : 559.13 ms/batch | loss  3.23 | perplexity 25.27\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkdBHwgQJh_D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "e0c32983-c699-4689-d6cf-e799396e04a8"
      },
      "source": [
        "criterion = LabelSmoothing(\n",
        "    size=len(SRC.vocab), padding_idx=src_pad, smoothing=0.1).to(device)\n",
        "optimizer = DynamicOptimizer(es_model.core.d_model, 1, 2000,\n",
        "                              torch.optim.Adam(es_model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))\n",
        "compute_loss = LossCompute(es_model.generator, criterion, optimizer)\n",
        "\n",
        "es_model.eval()\n",
        "es_valid_loss = run_epoch(\n",
        "    es_model, (make_batch(b, tgt_pad, src_pad, device)\n",
        "            for b in test_itr_es),\n",
        "    LossCompute(es_model.generator, criterion, None), 100, device)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step   100 : 578.80 ms/batch | loss  3.42 | perplexity 30.54\n",
            "Step   200 : 559.77 ms/batch | loss  3.56 | perplexity 35.31\n",
            "Step   300 : 568.90 ms/batch | loss  3.37 | perplexity 29.18\n",
            "Step   400 : 552.22 ms/batch | loss  3.13 | perplexity 22.77\n",
            "Step   500 : 561.16 ms/batch | loss  3.11 | perplexity 22.40\n",
            "Step   600 : 553.34 ms/batch | loss  3.63 | perplexity 37.54\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHWmINZWMCiW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "18a72478-0316-4212-cf80-b73bae7ae752"
      },
      "source": [
        "print(\"Modelo EN-ES: loss {}, perplexity {}\".format(en_valid_loss, math.exp(en_valid_loss)))\n",
        "print(\"Modelo ES-EN: loss {}, perplexity {}\".format(es_valid_loss, math.exp(es_valid_loss)))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Modelo EN-ES: loss 3.286382731767633, perplexity 26.74594122083582\n",
            "Modelo ES-EN: loss 3.4734340892962194, perplexity 32.247292598905716\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUbDic0m_bFg",
        "colab_type": "text"
      },
      "source": [
        "### Translate some sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAL31w7r_akR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 732
        },
        "outputId": "99fec174-b183-4136-b2a9-10477ddb2cef"
      },
      "source": [
        "sos = SRC.vocab.stoi['<s>']\n",
        "eos = SRC.vocab.stoi['</s>']\n",
        "translate_dataset(en_model, test_en, SRC, TGT, sos, eos, tgt_pad, device, 5)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Src:  <s>Because, what, hopefully, will, be, some, form, of, solution, will, be, in, the, nature, of, a, compromise, ,, I, also, think, it, would, be, entirely, reasonable, to, establish, a, deadline, ,, for, example, a, couple, of, years, from, now, ,, by, which, this, compromise, should, have, been, evaluated, so, that, we, can, really, see, if, it, is, operating, well, and, ,, if, it, is, not, ,, can, develop, and, improve, it, .</s>\n",
            "Candidates:\n",
            "Translation: <s>, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿ - score: -131.986083984375\n",
            "Translation: <s>, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, Muchas, ¿, ¿, ¿, ¿, ¿, ¿ - score: -132.8208818435669\n",
            "Translation: <s>, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, Muchas - score: -132.82088232040405\n",
            "Translation: <s>, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, Muchas, ¿, ¿, ¿, ¿, ¿ - score: -132.8208818435669\n",
            "Translation: <s>, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, Muchas, ¿ - score: -132.82088232040405\n",
            "\n",
            "Src:  <s>This, is, a, reason, to, rejoice, .</s>\n",
            "Candidates:\n",
            "Translation: <s>, ¿, ¿, ¿, ¿, ¿, ¿, ¿ - score: -12.832422733306885\n",
            "Translation: <s>, ¿, ¿, ¿, Muchas, ¿, ¿, ¿ - score: -13.667215347290039\n",
            "Translation: <s>, ¿, ¿, ¿, ¿, ¿, ¿, Muchas - score: -13.667215347290039\n",
            "Translation: <s>, ¿, ¿, Muchas, ¿, ¿, ¿, ¿ - score: -13.667215347290039\n",
            "Translation: <s>, ¿, ¿, ¿, ¿, ¿, Muchas, ¿ - score: -13.667215347290039\n",
            "\n",
            "Src:  <s>You, spoke, about, Fascist, forces, .</s>\n",
            "Candidates:\n",
            "Translation: <s>, ¿, ¿, ¿, ¿, ¿, ¿ - score: -10.996351718902588\n",
            "Translation: <s>, Muchas, ¿, ¿, ¿, ¿, ¿ - score: -11.83121919631958\n",
            "Translation: <s>, ¿, ¿, ¿, ¿, ¿, Muchas - score: -11.831219673156738\n",
            "Translation: <s>, ¿, ¿, ¿, Muchas, ¿, ¿ - score: -11.831219673156738\n",
            "Translation: <s>, ¿, ¿, ¿, ¿, Muchas, ¿ - score: -11.831219673156738\n",
            "\n",
            "Src:  <s>Clearly, a, lot, still, needs, to, be, done, ,, and, we, have, to, take, advantage, of, the, current, crisis, to, perhaps, change, the, emphasis, in, our, work, .</s>\n",
            "Candidates:\n",
            "Translation: <s>, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿ - score: -51.317193031311035\n",
            "Translation: <s>, ¿, Muchas, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿ - score: -52.15205430984497\n",
            "Translation: <s>, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, Muchas - score: -52.15205478668213\n",
            "Translation: <s>, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, Muchas, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿ - score: -52.15205478668213\n",
            "Translation: <s>, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, Muchas, ¿ - score: -52.15205478668213\n",
            "\n",
            "Src:  <s>I, do, not, ,, however, ,, accept, that, label, with, regard, to, this, report, ;, as, the, essence, of, this, report, is, a, rational, recommendation, ,, an, evaluation, .</s>\n",
            "Candidates:\n",
            "Translation: <s>, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿ - score: -53.16106939315796\n",
            "Translation: <s>, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, Muchas, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿ - score: -53.995872497558594\n",
            "Translation: <s>, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, Muchas - score: -53.995872497558594\n",
            "Translation: <s>, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, Muchas, ¿, ¿, ¿, ¿ - score: -53.995872497558594\n",
            "Translation: <s>, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, ¿, Muchas, ¿ - score: -53.995872497558594\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}