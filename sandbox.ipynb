{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python38264bittranslationdetectorhiqwxbpzvenv4b85a69a239941bfb36f97ba6eeac7ae",
      "display_name": "Python 3.8.2 64-bit ('TranslationDetector-hIqwxbpz': venv)"
    },
    "colab": {
      "name": "sandbox.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pablogadhi/TranslationDetector/blob/master/sandbox.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uG8TzpWkX1nO",
        "colab_type": "code",
        "outputId": "f95bbab6-fb83-4361-99e4-0992277f9171",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!git clone https://github.com/pablogadhi/TranslationDetector\n",
        "!python -m spacy download en\n",
        "!python -m spacy download es\n",
        "%cd TranslationDetector\n",
        "!pip install --upgrade torch torchtext"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'TranslationDetector'...\n",
            "remote: Enumerating objects: 85, done.\u001b[K\n",
            "remote: Counting objects: 100% (85/85), done.\u001b[K\n",
            "remote: Compressing objects: 100% (59/59), done.\u001b[K\n",
            "remote: Total 85 (delta 44), reused 58 (delta 25), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (85/85), done.\n",
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (47.1.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.6.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n",
            "Collecting es_core_news_sm==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-2.2.5/es_core_news_sm-2.2.5.tar.gz (16.2MB)\n",
            "\u001b[K     |████████████████████████████████| 16.2MB 1.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from es_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (0.6.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (47.1.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->es_core_news_sm==2.2.5) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->es_core_news_sm==2.2.5) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->es_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->es_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->es_core_news_sm==2.2.5) (1.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->es_core_news_sm==2.2.5) (3.1.0)\n",
            "Building wheels for collected packages: es-core-news-sm\n",
            "  Building wheel for es-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for es-core-news-sm: filename=es_core_news_sm-2.2.5-cp36-none-any.whl size=16172936 sha256=e97efbf9ce2cac58603c16dfb4c833b4f403f24cd734bddbc7aff38b79b3ba58\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-rikwnu56/wheels/05/4f/66/9d0c806f86de08e8645d67996798c49e1512f9c3a250d74242\n",
            "Successfully built es-core-news-sm\n",
            "Installing collected packages: es-core-news-sm\n",
            "Successfully installed es-core-news-sm-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('es_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/es_core_news_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/es\n",
            "You can now load the model via spacy.load('es')\n",
            "/content/TranslationDetector\n",
            "Requirement already up-to-date: torch in /usr/local/lib/python3.6/dist-packages (1.5.0+cu101)\n",
            "Collecting torchtext\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/17/e7c588245aece7aa93f360894179374830daf60d7ed0bbb59332de3b3b61/torchtext-0.6.0-py3-none-any.whl (64kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 5.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext) (4.41.1)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 24.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from torchtext) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from torchtext) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2020.4.5.1)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2.9)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (3.0.4)\n",
            "Installing collected packages: sentencepiece, torchtext\n",
            "  Found existing installation: torchtext 0.3.1\n",
            "    Uninstalling torchtext-0.3.1:\n",
            "      Successfully uninstalled torchtext-0.3.1\n",
            "Successfully installed sentencepiece-0.1.91 torchtext-0.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0FtCASL4cnB",
        "colab_type": "code",
        "outputId": "f7f1509a-0d40-41b2-be15-c91a56f28519",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PE1l5dNzZ_64",
        "colab_type": "code",
        "outputId": "f76f1bec-79b8-432b-db48-e2db47723a27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!git pull"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-xIrWVKXwyc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from translation.train import train_model\n",
        "from translation.data_loader import load_data, make_iters\n",
        "from translation.transformer import Transformer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vi40z2LrXwym",
        "colab_type": "code",
        "outputId": "e9e8f775-ee3f-4a35-a3eb-56dbbc3ce2c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CLkwuwc5VBQ",
        "colab_type": "code",
        "outputId": "5513b5c8-01e0-4672-f437-afae9440a942",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Jun 11 17:51:29 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P8    12W /  70W |     10MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUn26OeiXwyw",
        "colab_type": "text"
      },
      "source": [
        "### Load data and create the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtOFq2VT4tyK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_DIR='/content/drive/My Drive/NLP/data/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ixf7Ff4_Xwyx",
        "colab_type": "code",
        "outputId": "d08502e9-8658-4faf-d3cd-7f7f0376fc5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "SRC, TGT, train, valid, test = load_data(\n",
        "        DATA_DIR + \"en-es-0_\", \"en.txt\", \"es.txt\", DATA_DIR + \"SRC_Field.pt\", DATA_DIR + \"TGT_Field.pt\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "Data loaded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_c_45HZAXwy4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_itr, valid_itr, test_itr = make_iters(\n",
        "        train, valid, test, device, batch_size=4000)\n",
        "model = Transformer(len(SRC.vocab), len(TGT.vocab)).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbNzEw9xXwzJ",
        "colab_type": "code",
        "outputId": "43f50144-9af4-4dc0-aebc-93ae4cedfb20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(SRC.vocab.itos)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLQ7ImaaXwzN",
        "colab_type": "text"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SF1CDRaYXwzO",
        "colab_type": "code",
        "outputId": "1340302e-3052-4de8-d67a-b2e5fd5f99ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_model(model, train_itr, valid_itr, SRC, TGT, device, 10, save_at=1, checkpoint_f=DATA_DIR + \"checkpoint.pt\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
            "\tnonzero(Tensor input, *, Tensor out)\n",
            "Consider using one of the following signatures instead:\n",
            "\tnonzero(Tensor input, *, bool as_tuple)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step    50 : 637.76 ms/batch | loss  7.90\n",
            "Step   100 : 603.73 ms/batch | loss  6.86\n",
            "Step   150 : 626.49 ms/batch | loss  5.98\n",
            "Step   200 : 630.16 ms/batch | loss  5.56\n",
            "Step   250 : 626.25 ms/batch | loss  5.30\n",
            "Step   300 : 633.51 ms/batch | loss  4.92\n",
            "Step   350 : 632.51 ms/batch | loss  4.89\n",
            "Step   400 : 630.21 ms/batch | loss  4.66\n",
            "Step   450 : 635.45 ms/batch | loss  4.73\n",
            "Step   500 : 631.66 ms/batch | loss  4.30\n",
            "Step   550 : 633.43 ms/batch | loss  4.36\n",
            "Step   600 : 626.58 ms/batch | loss  4.36\n",
            "Step   650 : 626.53 ms/batch | loss  3.98\n",
            "Step   700 : 625.12 ms/batch | loss  4.11\n",
            "Step   750 : 631.54 ms/batch | loss  4.37\n",
            "Step   800 : 630.59 ms/batch | loss  4.28\n",
            "Step   850 : 634.83 ms/batch | loss  4.19\n",
            "Step   900 : 634.47 ms/batch | loss  4.25\n",
            "Step   950 : 631.35 ms/batch | loss  4.06\n",
            "Step  1000 : 625.05 ms/batch | loss  3.75\n",
            "Step  1050 : 634.59 ms/batch | loss  4.22\n",
            "Step  1100 : 626.64 ms/batch | loss  3.68\n",
            "Step  1150 : 631.85 ms/batch | loss  4.02\n",
            "Step  1200 : 626.60 ms/batch | loss  4.04\n",
            "Step  1250 : 628.73 ms/batch | loss  3.91\n",
            "Step  1300 : 633.19 ms/batch | loss  4.22\n",
            "Step  1350 : 632.21 ms/batch | loss  4.00\n",
            "Step  1400 : 629.45 ms/batch | loss  3.74\n",
            "Step  1450 : 628.67 ms/batch | loss  3.74\n",
            "Step  1500 : 628.39 ms/batch | loss  3.96\n",
            "Step  1550 : 626.34 ms/batch | loss  3.88\n",
            "Step  1600 : 623.47 ms/batch | loss  3.74\n",
            "Step  1650 : 627.74 ms/batch | loss  3.76\n",
            "Step  1700 : 628.18 ms/batch | loss  3.74\n",
            "Step  1750 : 629.23 ms/batch | loss  3.85\n",
            "Step  1800 : 623.19 ms/batch | loss  4.01\n",
            "Step  1850 : 634.31 ms/batch | loss  3.68\n",
            "Step  1900 : 627.94 ms/batch | loss  4.07\n",
            "Step  1950 : 631.52 ms/batch | loss  3.74\n",
            "Step  2000 : 624.74 ms/batch | loss  3.56\n",
            "Step  2050 : 623.32 ms/batch | loss  3.76\n",
            "Step  2100 : 623.75 ms/batch | loss  3.58\n",
            "Step  2150 : 623.78 ms/batch | loss  3.73\n",
            "Step  2200 : 627.64 ms/batch | loss  3.71\n",
            "Step  2250 : 622.92 ms/batch | loss  3.37\n",
            "Step  2300 : 628.54 ms/batch | loss  3.71\n",
            "Step  2350 : 623.61 ms/batch | loss  3.76\n",
            "Step  2400 : 618.91 ms/batch | loss  3.86\n",
            "Step  2450 : 616.81 ms/batch | loss  3.83\n",
            "Step  2500 : 612.18 ms/batch | loss  3.70\n",
            "Step  2550 : 628.79 ms/batch | loss  3.51\n",
            "Step  2600 : 628.68 ms/batch | loss  3.70\n",
            "Step  2650 : 627.34 ms/batch | loss  3.40\n",
            "Step  2700 : 629.44 ms/batch | loss  3.66\n",
            "Step  2750 : 613.55 ms/batch | loss  3.74\n",
            "Step  2800 : 622.78 ms/batch | loss  3.58\n",
            "Step    50 : 592.00 ms/batch | loss  3.60\n",
            "Step   100 : 578.73 ms/batch | loss  3.67\n",
            "Step   150 : 573.80 ms/batch | loss  3.75\n",
            "Step   200 : 575.89 ms/batch | loss  4.00\n",
            "Step   250 : 580.26 ms/batch | loss  3.67\n",
            "Step   300 : 584.90 ms/batch | loss  3.84\n",
            "Step   350 : 577.42 ms/batch | loss  3.87\n",
            "Step   400 : 576.23 ms/batch | loss  3.70\n",
            "Step   450 : 565.57 ms/batch | loss  3.84\n",
            "Step   500 : 585.85 ms/batch | loss  3.65\n",
            "Step   550 : 575.07 ms/batch | loss  4.05\n",
            "Step   600 : 564.89 ms/batch | loss  3.93\n",
            "Epoch: 01\n",
            "\tTrain Loss: 4.223\n",
            "\t Val. Loss: 3.741\n",
            "Model saved!\n",
            "Step    50 : 672.68 ms/batch | loss  4.25\n",
            "Step   100 : 625.65 ms/batch | loss  3.52\n",
            "Step   150 : 616.02 ms/batch | loss  3.63\n",
            "Step   200 : 629.58 ms/batch | loss  3.82\n",
            "Step   250 : 628.12 ms/batch | loss  3.79\n",
            "Step   300 : 628.96 ms/batch | loss  3.54\n",
            "Step   350 : 625.93 ms/batch | loss  3.69\n",
            "Step   400 : 629.54 ms/batch | loss  3.94\n",
            "Step   450 : 622.21 ms/batch | loss  3.91\n",
            "Step   500 : 620.33 ms/batch | loss  3.51\n",
            "Step   550 : 625.96 ms/batch | loss  3.57\n",
            "Step   600 : 627.48 ms/batch | loss  3.74\n",
            "Step   650 : 622.38 ms/batch | loss  3.80\n",
            "Step   700 : 624.44 ms/batch | loss  3.54\n",
            "Step   750 : 630.57 ms/batch | loss  3.92\n",
            "Step   800 : 624.41 ms/batch | loss  3.75\n",
            "Step   850 : 625.18 ms/batch | loss  3.74\n",
            "Step   900 : 626.13 ms/batch | loss  3.72\n",
            "Step   950 : 625.44 ms/batch | loss  3.54\n",
            "Step  1000 : 625.37 ms/batch | loss  3.32\n",
            "Step  1050 : 624.18 ms/batch | loss  3.65\n",
            "Step  1100 : 620.83 ms/batch | loss  3.66\n",
            "Step  1150 : 623.73 ms/batch | loss  3.67\n",
            "Step  1200 : 617.76 ms/batch | loss  3.67\n",
            "Step  1250 : 628.35 ms/batch | loss  3.74\n",
            "Step  1300 : 618.84 ms/batch | loss  3.61\n",
            "Step  1350 : 626.67 ms/batch | loss  3.54\n",
            "Step  1400 : 625.35 ms/batch | loss  3.14\n",
            "Step  1450 : 617.19 ms/batch | loss  3.66\n",
            "Step  1500 : 623.11 ms/batch | loss  3.56\n",
            "Step  1550 : 627.00 ms/batch | loss  3.51\n",
            "Step  1600 : 625.21 ms/batch | loss  3.43\n",
            "Step  1650 : 629.52 ms/batch | loss  3.52\n",
            "Step  1700 : 628.96 ms/batch | loss  3.60\n",
            "Step  1750 : 622.97 ms/batch | loss  3.51\n",
            "Step  1800 : 628.30 ms/batch | loss  3.56\n",
            "Step  1850 : 625.58 ms/batch | loss  3.46\n",
            "Step  1900 : 623.67 ms/batch | loss  3.38\n",
            "Step  1950 : 625.02 ms/batch | loss  3.44\n",
            "Step  2000 : 625.40 ms/batch | loss  3.52\n",
            "Step  2050 : 620.69 ms/batch | loss  2.98\n",
            "Step  2100 : 625.11 ms/batch | loss  3.53\n",
            "Step  2150 : 620.86 ms/batch | loss  3.54\n",
            "Step  2200 : 625.59 ms/batch | loss  3.58\n",
            "Step  2250 : 621.96 ms/batch | loss  3.47\n",
            "Step  2300 : 628.32 ms/batch | loss  3.72\n",
            "Step  2350 : 612.58 ms/batch | loss  3.67\n",
            "Step  2400 : 622.02 ms/batch | loss  3.55\n",
            "Step  2450 : 619.80 ms/batch | loss  3.55\n",
            "Step  2500 : 622.59 ms/batch | loss  3.37\n",
            "Step  2550 : 625.33 ms/batch | loss  3.58\n",
            "Step  2600 : 626.26 ms/batch | loss  3.79\n",
            "Step  2650 : 623.15 ms/batch | loss  3.51\n",
            "Step  2700 : 625.61 ms/batch | loss  3.62\n",
            "Step  2750 : 630.24 ms/batch | loss  3.55\n",
            "Step  2800 : 618.64 ms/batch | loss  3.35\n",
            "Step    50 : 589.61 ms/batch | loss  3.75\n",
            "Step   100 : 569.53 ms/batch | loss  3.63\n",
            "Step   150 : 575.89 ms/batch | loss  4.02\n",
            "Step   200 : 572.33 ms/batch | loss  3.85\n",
            "Step   250 : 572.85 ms/batch | loss  3.69\n",
            "Step   300 : 567.58 ms/batch | loss  3.82\n",
            "Step   350 : 572.37 ms/batch | loss  3.99\n",
            "Step   400 : 575.88 ms/batch | loss  3.49\n",
            "Step   450 : 575.64 ms/batch | loss  3.89\n",
            "Step   500 : 564.54 ms/batch | loss  3.59\n",
            "Step   550 : 561.85 ms/batch | loss  3.84\n",
            "Step   600 : 577.17 ms/batch | loss  3.55\n",
            "Epoch: 02\n",
            "\tTrain Loss: 3.630\n",
            "\t Val. Loss: 3.709\n",
            "Model saved!\n",
            "Step    50 : 668.99 ms/batch | loss  3.58\n",
            "Step   100 : 622.87 ms/batch | loss  3.29\n",
            "Step   150 : 619.02 ms/batch | loss  3.39\n",
            "Step   200 : 624.42 ms/batch | loss  3.42\n",
            "Step   250 : 623.18 ms/batch | loss  3.25\n",
            "Step   300 : 628.35 ms/batch | loss  3.54\n",
            "Step   350 : 628.53 ms/batch | loss  3.29\n",
            "Step   400 : 626.81 ms/batch | loss  3.13\n",
            "Step   450 : 625.26 ms/batch | loss  3.43\n",
            "Step   500 : 621.56 ms/batch | loss  3.52\n",
            "Step   550 : 628.76 ms/batch | loss  3.62\n",
            "Step   600 : 624.13 ms/batch | loss  3.40\n",
            "Step   650 : 622.70 ms/batch | loss  3.48\n",
            "Step   700 : 624.00 ms/batch | loss  3.26\n",
            "Step   750 : 627.12 ms/batch | loss  3.38\n",
            "Step   800 : 617.91 ms/batch | loss  2.98\n",
            "Step   850 : 621.68 ms/batch | loss  3.37\n",
            "Step   900 : 621.88 ms/batch | loss  3.14\n",
            "Step   950 : 628.68 ms/batch | loss  3.31\n",
            "Step  1000 : 630.64 ms/batch | loss  3.51\n",
            "Step  1050 : 621.55 ms/batch | loss  3.40\n",
            "Step  1100 : 618.60 ms/batch | loss  3.47\n",
            "Step  1150 : 623.38 ms/batch | loss  3.38\n",
            "Step  1200 : 627.33 ms/batch | loss  3.60\n",
            "Step  1250 : 618.06 ms/batch | loss  3.71\n",
            "Step  1300 : 619.88 ms/batch | loss  3.59\n",
            "Step  1350 : 622.27 ms/batch | loss  3.39\n",
            "Step  1400 : 621.59 ms/batch | loss  3.55\n",
            "Step  1450 : 620.74 ms/batch | loss  3.04\n",
            "Step  1500 : 626.14 ms/batch | loss  3.44\n",
            "Step  1550 : 625.89 ms/batch | loss  3.43\n",
            "Step  1600 : 620.50 ms/batch | loss  3.00\n",
            "Step  1650 : 624.93 ms/batch | loss  3.61\n",
            "Step  1700 : 619.73 ms/batch | loss  3.44\n",
            "Step  1750 : 620.60 ms/batch | loss  3.34\n",
            "Step  1800 : 631.41 ms/batch | loss  3.56\n",
            "Step  1850 : 623.78 ms/batch | loss  3.62\n",
            "Step  1900 : 624.07 ms/batch | loss  3.50\n",
            "Step  1950 : 616.83 ms/batch | loss  3.03\n",
            "Step  2000 : 624.86 ms/batch | loss  2.72\n",
            "Step  2050 : 619.32 ms/batch | loss  3.43\n",
            "Step  2100 : 621.39 ms/batch | loss  3.26\n",
            "Step  2150 : 628.53 ms/batch | loss  3.41\n",
            "Step  2200 : 627.12 ms/batch | loss  3.38\n",
            "Step  2250 : 624.36 ms/batch | loss  3.46\n",
            "Step  2300 : 622.41 ms/batch | loss  3.59\n",
            "Step  2350 : 623.03 ms/batch | loss  3.28\n",
            "Step  2400 : 617.26 ms/batch | loss  3.59\n",
            "Step  2450 : 626.95 ms/batch | loss  3.34\n",
            "Step  2500 : 620.07 ms/batch | loss  3.21\n",
            "Step  2550 : 620.10 ms/batch | loss  3.53\n",
            "Step  2600 : 620.95 ms/batch | loss  3.29\n",
            "Step  2650 : 619.42 ms/batch | loss  3.40\n",
            "Step  2700 : 625.45 ms/batch | loss  3.42\n",
            "Step  2750 : 614.31 ms/batch | loss  3.56\n",
            "Step  2800 : 622.21 ms/batch | loss  3.34\n",
            "Step    50 : 587.82 ms/batch | loss  3.68\n",
            "Step   100 : 567.88 ms/batch | loss  3.52\n",
            "Step   150 : 568.97 ms/batch | loss  3.54\n",
            "Step   200 : 556.14 ms/batch | loss  2.74\n",
            "Step   250 : 566.22 ms/batch | loss  3.61\n",
            "Step   300 : 569.32 ms/batch | loss  3.70\n",
            "Step   350 : 571.72 ms/batch | loss  2.67\n",
            "Step   400 : 576.78 ms/batch | loss  3.56\n",
            "Step   450 : 564.24 ms/batch | loss  3.93\n",
            "Step   500 : 574.51 ms/batch | loss  3.51\n",
            "Step   550 : 569.73 ms/batch | loss  3.50\n",
            "Step   600 : 569.07 ms/batch | loss  3.59\n",
            "Epoch: 03\n",
            "\tTrain Loss: 3.409\n",
            "\t Val. Loss: 3.642\n",
            "Model saved!\n",
            "Step    50 : 677.52 ms/batch | loss  3.51\n",
            "Step   100 : 616.85 ms/batch | loss  3.48\n",
            "Step   150 : 624.99 ms/batch | loss  3.49\n",
            "Step   200 : 617.63 ms/batch | loss  2.95\n",
            "Step   250 : 623.93 ms/batch | loss  3.28\n",
            "Step   300 : 621.22 ms/batch | loss  3.56\n",
            "Step   350 : 627.63 ms/batch | loss  3.62\n",
            "Step   400 : 616.51 ms/batch | loss  3.27\n",
            "Step   450 : 622.12 ms/batch | loss  3.51\n",
            "Step   500 : 622.92 ms/batch | loss  3.06\n",
            "Step   550 : 618.53 ms/batch | loss  3.29\n",
            "Step   600 : 617.63 ms/batch | loss  3.35\n",
            "Step   650 : 623.56 ms/batch | loss  3.32\n",
            "Step   700 : 628.08 ms/batch | loss  3.19\n",
            "Step   750 : 620.55 ms/batch | loss  3.46\n",
            "Step   800 : 616.95 ms/batch | loss  3.54\n",
            "Step   850 : 625.76 ms/batch | loss  3.35\n",
            "Step   900 : 621.05 ms/batch | loss  2.64\n",
            "Step   950 : 620.65 ms/batch | loss  2.91\n",
            "Step  1000 : 623.50 ms/batch | loss  3.40\n",
            "Step  1050 : 619.89 ms/batch | loss  3.27\n",
            "Step  1100 : 625.22 ms/batch | loss  3.33\n",
            "Step  1150 : 630.58 ms/batch | loss  3.21\n",
            "Step  1200 : 624.98 ms/batch | loss  3.34\n",
            "Step  1250 : 623.02 ms/batch | loss  3.43\n",
            "Step  1300 : 625.01 ms/batch | loss  3.30\n",
            "Step  1350 : 625.53 ms/batch | loss  3.29\n",
            "Step  1400 : 622.40 ms/batch | loss  3.30\n",
            "Step  1450 : 621.76 ms/batch | loss  3.39\n",
            "Step  1500 : 623.94 ms/batch | loss  3.27\n",
            "Step  1550 : 620.03 ms/batch | loss  3.31\n",
            "Step  1600 : 620.72 ms/batch | loss  3.44\n",
            "Step  1650 : 620.33 ms/batch | loss  3.52\n",
            "Step  1700 : 618.29 ms/batch | loss  3.55\n",
            "Step  1750 : 619.72 ms/batch | loss  3.11\n",
            "Step  1800 : 628.00 ms/batch | loss  3.23\n",
            "Step  1850 : 621.13 ms/batch | loss  3.15\n",
            "Step  1900 : 624.34 ms/batch | loss  3.52\n",
            "Step  1950 : 614.16 ms/batch | loss  3.35\n",
            "Step  2000 : 623.24 ms/batch | loss  3.36\n",
            "Step  2050 : 618.90 ms/batch | loss  3.13\n",
            "Step  2100 : 622.23 ms/batch | loss  3.41\n",
            "Step  2150 : 621.33 ms/batch | loss  3.57\n",
            "Step  2200 : 615.82 ms/batch | loss  3.60\n",
            "Step  2250 : 624.51 ms/batch | loss  3.48\n",
            "Step  2300 : 625.87 ms/batch | loss  3.23\n",
            "Step  2350 : 618.76 ms/batch | loss  3.25\n",
            "Step  2400 : 622.23 ms/batch | loss  3.45\n",
            "Step  2450 : 621.71 ms/batch | loss  3.03\n",
            "Step  2500 : 626.86 ms/batch | loss  3.18\n",
            "Step  2550 : 625.82 ms/batch | loss  3.38\n",
            "Step  2600 : 620.82 ms/batch | loss  3.23\n",
            "Step  2650 : 614.24 ms/batch | loss  3.35\n",
            "Step  2700 : 620.59 ms/batch | loss  3.39\n",
            "Step  2750 : 621.25 ms/batch | loss  3.31\n",
            "Step  2800 : 618.46 ms/batch | loss  3.45\n",
            "Step    50 : 576.49 ms/batch | loss  3.55\n",
            "Step   100 : 557.93 ms/batch | loss  3.61\n",
            "Step   150 : 566.18 ms/batch | loss  3.63\n",
            "Step   200 : 558.76 ms/batch | loss  3.92\n",
            "Step   250 : 578.05 ms/batch | loss  3.73\n",
            "Step   300 : 574.32 ms/batch | loss  2.82\n",
            "Step   350 : 568.17 ms/batch | loss  3.73\n",
            "Step   400 : 574.84 ms/batch | loss  3.91\n",
            "Step   450 : 566.05 ms/batch | loss  3.89\n",
            "Step   500 : 563.50 ms/batch | loss  3.73\n",
            "Step   550 : 566.87 ms/batch | loss  3.54\n",
            "Step   600 : 579.59 ms/batch | loss  3.97\n",
            "Epoch: 04\n",
            "\tTrain Loss: 3.304\n",
            "\t Val. Loss: 3.775\n",
            "Model saved!\n",
            "Step    50 : 675.52 ms/batch | loss  3.39\n",
            "Step   100 : 614.05 ms/batch | loss  3.24\n",
            "Step   150 : 619.82 ms/batch | loss  3.38\n",
            "Step   200 : 621.73 ms/batch | loss  3.22\n",
            "Step   250 : 629.05 ms/batch | loss  2.93\n",
            "Step   300 : 626.20 ms/batch | loss  3.30\n",
            "Step   350 : 626.84 ms/batch | loss  3.23\n",
            "Step   400 : 614.49 ms/batch | loss  3.29\n",
            "Step   450 : 622.46 ms/batch | loss  3.44\n",
            "Step   500 : 623.11 ms/batch | loss  3.16\n",
            "Step   550 : 616.07 ms/batch | loss  3.57\n",
            "Step   600 : 619.63 ms/batch | loss  3.23\n",
            "Step   650 : 621.16 ms/batch | loss  3.37\n",
            "Step   700 : 621.59 ms/batch | loss  3.38\n",
            "Step   750 : 627.63 ms/batch | loss  3.13\n",
            "Step   800 : 624.79 ms/batch | loss  3.22\n",
            "Step   850 : 625.09 ms/batch | loss  3.08\n",
            "Step   900 : 612.56 ms/batch | loss  2.30\n",
            "Step   950 : 623.01 ms/batch | loss  2.55\n",
            "Step  1000 : 627.89 ms/batch | loss  3.24\n",
            "Step  1050 : 622.40 ms/batch | loss  3.16\n",
            "Step  1100 : 623.70 ms/batch | loss  3.04\n",
            "Step  1150 : 627.70 ms/batch | loss  3.35\n",
            "Step  1200 : 621.71 ms/batch | loss  3.28\n",
            "Step  1250 : 629.70 ms/batch | loss  3.38\n",
            "Step  1300 : 620.43 ms/batch | loss  3.27\n",
            "Step  1350 : 623.10 ms/batch | loss  3.43\n",
            "Step  1400 : 623.76 ms/batch | loss  2.98\n",
            "Step  1450 : 624.04 ms/batch | loss  2.72\n",
            "Step  1500 : 623.75 ms/batch | loss  3.34\n",
            "Step  1550 : 620.98 ms/batch | loss  3.17\n",
            "Step  1600 : 622.09 ms/batch | loss  3.48\n",
            "Step  1650 : 630.08 ms/batch | loss  3.41\n",
            "Step  1700 : 618.63 ms/batch | loss  3.22\n",
            "Step  1750 : 625.56 ms/batch | loss  3.26\n",
            "Step  1800 : 621.51 ms/batch | loss  3.08\n",
            "Step  1850 : 623.32 ms/batch | loss  3.03\n",
            "Step  1900 : 628.74 ms/batch | loss  3.29\n",
            "Step  1950 : 614.07 ms/batch | loss  3.41\n",
            "Step  2000 : 622.00 ms/batch | loss  3.29\n",
            "Step  2050 : 621.13 ms/batch | loss  3.22\n",
            "Step  2100 : 623.16 ms/batch | loss  3.50\n",
            "Step  2150 : 622.54 ms/batch | loss  3.19\n",
            "Step  2200 : 617.86 ms/batch | loss  3.25\n",
            "Step  2250 : 619.27 ms/batch | loss  3.25\n",
            "Step  2300 : 629.61 ms/batch | loss  3.40\n",
            "Step  2350 : 620.09 ms/batch | loss  3.22\n",
            "Step  2400 : 621.09 ms/batch | loss  3.43\n",
            "Step  2450 : 624.30 ms/batch | loss  3.25\n",
            "Step  2500 : 627.92 ms/batch | loss  2.64\n",
            "Step  2550 : 616.74 ms/batch | loss  3.21\n",
            "Step  2600 : 624.76 ms/batch | loss  3.11\n",
            "Step  2650 : 621.86 ms/batch | loss  3.12\n",
            "Step  2700 : 620.38 ms/batch | loss  3.29\n",
            "Step  2750 : 625.52 ms/batch | loss  3.02\n",
            "Step  2800 : 626.61 ms/batch | loss  3.34\n",
            "Step    50 : 588.66 ms/batch | loss  3.26\n",
            "Step   100 : 568.03 ms/batch | loss  3.48\n",
            "Step   150 : 556.89 ms/batch | loss  3.67\n",
            "Step   200 : 574.86 ms/batch | loss  3.71\n",
            "Step   250 : 559.91 ms/batch | loss  3.36\n",
            "Step   300 : 567.55 ms/batch | loss  3.29\n",
            "Step   350 : 573.85 ms/batch | loss  3.73\n",
            "Step   400 : 575.78 ms/batch | loss  3.25\n",
            "Step   450 : 568.48 ms/batch | loss  3.18\n",
            "Step   500 : 569.44 ms/batch | loss  3.50\n",
            "Step   550 : 572.25 ms/batch | loss  3.43\n",
            "Step   600 : 580.75 ms/batch | loss  3.53\n",
            "Epoch: 05\n",
            "\tTrain Loss: 3.234\n",
            "\t Val. Loss: 3.524\n",
            "Model saved!\n",
            "Step    50 : 678.60 ms/batch | loss  3.28\n",
            "Step   100 : 626.18 ms/batch | loss  3.16\n",
            "Step   150 : 628.34 ms/batch | loss  3.10\n",
            "Step   200 : 623.80 ms/batch | loss  3.25\n",
            "Step   250 : 621.92 ms/batch | loss  3.48\n",
            "Step   300 : 621.18 ms/batch | loss  3.42\n",
            "Step   350 : 627.26 ms/batch | loss  3.09\n",
            "Step   400 : 623.17 ms/batch | loss  3.29\n",
            "Step   450 : 625.13 ms/batch | loss  2.97\n",
            "Step   500 : 618.61 ms/batch | loss  3.44\n",
            "Step   550 : 625.17 ms/batch | loss  3.09\n",
            "Step   600 : 619.95 ms/batch | loss  3.28\n",
            "Step   650 : 617.68 ms/batch | loss  3.18\n",
            "Step   700 : 619.80 ms/batch | loss  3.40\n",
            "Step   750 : 623.12 ms/batch | loss  3.16\n",
            "Step   800 : 627.89 ms/batch | loss  3.13\n",
            "Step   850 : 627.17 ms/batch | loss  3.38\n",
            "Step   900 : 626.53 ms/batch | loss  3.15\n",
            "Step   950 : 624.49 ms/batch | loss  2.87\n",
            "Step  1000 : 620.14 ms/batch | loss  3.00\n",
            "Step  1050 : 624.37 ms/batch | loss  2.89\n",
            "Step  1100 : 620.49 ms/batch | loss  3.22\n",
            "Step  1150 : 623.50 ms/batch | loss  3.31\n",
            "Step  1200 : 624.45 ms/batch | loss  3.18\n",
            "Step  1250 : 618.75 ms/batch | loss  3.26\n",
            "Step  1300 : 621.77 ms/batch | loss  3.23\n",
            "Step  1350 : 620.47 ms/batch | loss  3.07\n",
            "Step  1400 : 619.55 ms/batch | loss  3.18\n",
            "Step  1450 : 619.00 ms/batch | loss  3.46\n",
            "Step  1500 : 627.30 ms/batch | loss  3.08\n",
            "Step  1550 : 618.06 ms/batch | loss  3.41\n",
            "Step  1600 : 621.62 ms/batch | loss  3.21\n",
            "Step  1650 : 618.11 ms/batch | loss  3.04\n",
            "Step  1700 : 622.02 ms/batch | loss  2.90\n",
            "Step  1750 : 621.24 ms/batch | loss  3.14\n",
            "Step  1800 : 620.50 ms/batch | loss  3.23\n",
            "Step  1850 : 623.46 ms/batch | loss  3.27\n",
            "Step  1900 : 625.63 ms/batch | loss  3.33\n",
            "Step  1950 : 627.95 ms/batch | loss  3.32\n",
            "Step  2000 : 624.10 ms/batch | loss  3.11\n",
            "Step  2050 : 624.81 ms/batch | loss  2.89\n",
            "Step  2100 : 622.91 ms/batch | loss  3.16\n",
            "Step  2150 : 617.70 ms/batch | loss  3.06\n",
            "Step  2200 : 615.87 ms/batch | loss  2.98\n",
            "Step  2250 : 623.32 ms/batch | loss  3.39\n",
            "Step  2300 : 624.65 ms/batch | loss  3.22\n",
            "Step  2350 : 620.56 ms/batch | loss  3.03\n",
            "Step  2400 : 618.46 ms/batch | loss  3.19\n",
            "Step  2450 : 620.48 ms/batch | loss  3.42\n",
            "Step  2500 : 625.93 ms/batch | loss  2.94\n",
            "Step  2550 : 616.87 ms/batch | loss  3.39\n",
            "Step  2600 : 614.02 ms/batch | loss  3.53\n",
            "Step  2650 : 615.97 ms/batch | loss  3.24\n",
            "Step  2700 : 616.92 ms/batch | loss  3.57\n",
            "Step  2750 : 624.47 ms/batch | loss  3.21\n",
            "Step  2800 : 622.74 ms/batch | loss  3.38\n",
            "Step    50 : 588.98 ms/batch | loss  4.02\n",
            "Step   100 : 575.11 ms/batch | loss  3.51\n",
            "Step   150 : 560.57 ms/batch | loss  3.62\n",
            "Step   200 : 564.15 ms/batch | loss  3.95\n",
            "Step   250 : 554.03 ms/batch | loss  3.42\n",
            "Step   300 : 568.08 ms/batch | loss  3.31\n",
            "Step   350 : 576.71 ms/batch | loss  3.70\n",
            "Step   400 : 567.36 ms/batch | loss  3.72\n",
            "Step   450 : 555.50 ms/batch | loss  3.01\n",
            "Step   500 : 568.18 ms/batch | loss  3.62\n",
            "Step   550 : 577.29 ms/batch | loss  3.53\n",
            "Step   600 : 566.85 ms/batch | loss  3.41\n",
            "Epoch: 06\n",
            "\tTrain Loss: 3.184\n",
            "\t Val. Loss: 3.509\n",
            "Model saved!\n",
            "Step    50 : 675.26 ms/batch | loss  3.28\n",
            "Step   100 : 621.65 ms/batch | loss  3.04\n",
            "Step   150 : 627.95 ms/batch | loss  3.17\n",
            "Step   200 : 621.35 ms/batch | loss  2.96\n",
            "Step   250 : 619.74 ms/batch | loss  3.23\n",
            "Step   300 : 618.74 ms/batch | loss  2.97\n",
            "Step   350 : 620.45 ms/batch | loss  3.29\n",
            "Step   400 : 615.55 ms/batch | loss  3.10\n",
            "Step   450 : 627.63 ms/batch | loss  3.14\n",
            "Step   500 : 622.85 ms/batch | loss  3.12\n",
            "Step   550 : 619.52 ms/batch | loss  3.15\n",
            "Step   600 : 612.80 ms/batch | loss  3.13\n",
            "Step   650 : 619.64 ms/batch | loss  2.67\n",
            "Step   700 : 625.59 ms/batch | loss  3.41\n",
            "Step   750 : 618.64 ms/batch | loss  3.00\n",
            "Step   800 : 615.39 ms/batch | loss  3.09\n",
            "Step   850 : 623.57 ms/batch | loss  3.25\n",
            "Step   900 : 622.31 ms/batch | loss  3.13\n",
            "Step   950 : 620.05 ms/batch | loss  3.07\n",
            "Step  1000 : 620.38 ms/batch | loss  1.73\n",
            "Step  1050 : 627.02 ms/batch | loss  3.29\n",
            "Step  1100 : 618.55 ms/batch | loss  3.09\n",
            "Step  1150 : 618.66 ms/batch | loss  3.03\n",
            "Step  1200 : 616.58 ms/batch | loss  3.09\n",
            "Step  1250 : 624.57 ms/batch | loss  3.31\n",
            "Step  1300 : 619.40 ms/batch | loss  3.17\n",
            "Step  1350 : 621.32 ms/batch | loss  3.18\n",
            "Step  1400 : 621.12 ms/batch | loss  3.01\n",
            "Step  1450 : 616.10 ms/batch | loss  3.29\n",
            "Step  1500 : 613.50 ms/batch | loss  3.17\n",
            "Step  1550 : 624.23 ms/batch | loss  3.38\n",
            "Step  1600 : 625.75 ms/batch | loss  3.21\n",
            "Step  1650 : 625.05 ms/batch | loss  3.21\n",
            "Step  1700 : 624.83 ms/batch | loss  3.33\n",
            "Step  1750 : 620.32 ms/batch | loss  3.10\n",
            "Step  1800 : 619.71 ms/batch | loss  2.98\n",
            "Step  1850 : 615.00 ms/batch | loss  3.21\n",
            "Step  1900 : 624.66 ms/batch | loss  3.19\n",
            "Step  1950 : 625.78 ms/batch | loss  3.26\n",
            "Step  2000 : 620.90 ms/batch | loss  3.05\n",
            "Step  2050 : 627.30 ms/batch | loss  3.34\n",
            "Step  2100 : 627.44 ms/batch | loss  3.39\n",
            "Step  2150 : 620.03 ms/batch | loss  3.11\n",
            "Step  2200 : 619.86 ms/batch | loss  3.19\n",
            "Step  2250 : 627.24 ms/batch | loss  3.30\n",
            "Step  2300 : 618.56 ms/batch | loss  3.34\n",
            "Step  2350 : 622.81 ms/batch | loss  3.33\n",
            "Step  2400 : 625.42 ms/batch | loss  2.96\n",
            "Step  2450 : 619.89 ms/batch | loss  2.89\n",
            "Step  2500 : 626.77 ms/batch | loss  2.93\n",
            "Step  2550 : 621.12 ms/batch | loss  2.57\n",
            "Step  2600 : 622.06 ms/batch | loss  2.91\n",
            "Step  2650 : 618.06 ms/batch | loss  2.81\n",
            "Step  2700 : 620.28 ms/batch | loss  3.17\n",
            "Step  2750 : 620.69 ms/batch | loss  3.22\n",
            "Step  2800 : 627.06 ms/batch | loss  3.15\n",
            "Step    50 : 593.09 ms/batch | loss  3.67\n",
            "Step   100 : 568.42 ms/batch | loss  3.79\n",
            "Step   150 : 568.23 ms/batch | loss  3.31\n",
            "Step   200 : 573.57 ms/batch | loss  3.61\n",
            "Step   250 : 567.96 ms/batch | loss  3.60\n",
            "Step   300 : 570.77 ms/batch | loss  3.82\n",
            "Step   350 : 568.69 ms/batch | loss  3.60\n",
            "Step   400 : 578.19 ms/batch | loss  3.74\n",
            "Step   450 : 572.58 ms/batch | loss  3.56\n",
            "Step   500 : 564.08 ms/batch | loss  3.83\n",
            "Step   550 : 570.51 ms/batch | loss  3.62\n",
            "Step   600 : 568.56 ms/batch | loss  3.57\n",
            "Epoch: 07\n",
            "\tTrain Loss: 3.145\n",
            "\t Val. Loss: 3.522\n",
            "Model saved!\n",
            "Step    50 : 675.03 ms/batch | loss  3.23\n",
            "Step   100 : 619.87 ms/batch | loss  2.90\n",
            "Step   150 : 624.50 ms/batch | loss  3.14\n",
            "Step   200 : 619.62 ms/batch | loss  3.13\n",
            "Step   250 : 624.72 ms/batch | loss  2.96\n",
            "Step   300 : 626.65 ms/batch | loss  3.01\n",
            "Step   350 : 618.14 ms/batch | loss  3.16\n",
            "Step   400 : 613.15 ms/batch | loss  3.26\n",
            "Step   450 : 624.13 ms/batch | loss  3.09\n",
            "Step   500 : 625.64 ms/batch | loss  3.25\n",
            "Step   550 : 624.17 ms/batch | loss  2.96\n",
            "Step   600 : 619.76 ms/batch | loss  2.53\n",
            "Step   650 : 624.33 ms/batch | loss  1.86\n",
            "Step   700 : 625.46 ms/batch | loss  3.04\n",
            "Step   750 : 621.76 ms/batch | loss  3.37\n",
            "Step   800 : 624.49 ms/batch | loss  3.05\n",
            "Step   850 : 623.59 ms/batch | loss  2.83\n",
            "Step   900 : 620.99 ms/batch | loss  3.14\n",
            "Step   950 : 625.08 ms/batch | loss  3.33\n",
            "Step  1000 : 614.25 ms/batch | loss  3.02\n",
            "Step  1050 : 620.90 ms/batch | loss  3.10\n",
            "Step  1100 : 619.44 ms/batch | loss  2.98\n",
            "Step  1150 : 623.62 ms/batch | loss  3.16\n",
            "Step  1200 : 623.86 ms/batch | loss  3.13\n",
            "Step  1250 : 619.25 ms/batch | loss  3.03\n",
            "Step  1300 : 623.96 ms/batch | loss  3.06\n",
            "Step  1350 : 628.83 ms/batch | loss  3.10\n",
            "Step  1400 : 623.98 ms/batch | loss  3.39\n",
            "Step  1450 : 632.66 ms/batch | loss  3.20\n",
            "Step  1500 : 626.15 ms/batch | loss  3.02\n",
            "Step  1550 : 623.05 ms/batch | loss  3.22\n",
            "Step  1600 : 628.65 ms/batch | loss  3.19\n",
            "Step  1650 : 626.32 ms/batch | loss  3.24\n",
            "Step  1700 : 622.36 ms/batch | loss  3.19\n",
            "Step  1750 : 625.18 ms/batch | loss  2.85\n",
            "Step  1800 : 627.45 ms/batch | loss  3.27\n",
            "Step  1850 : 616.42 ms/batch | loss  3.26\n",
            "Step  1900 : 622.26 ms/batch | loss  3.24\n",
            "Step  1950 : 627.01 ms/batch | loss  3.09\n",
            "Step  2000 : 621.34 ms/batch | loss  3.15\n",
            "Step  2050 : 625.38 ms/batch | loss  3.17\n",
            "Step  2100 : 624.78 ms/batch | loss  2.96\n",
            "Step  2150 : 619.98 ms/batch | loss  3.46\n",
            "Step  2200 : 620.62 ms/batch | loss  3.13\n",
            "Step  2250 : 617.69 ms/batch | loss  3.11\n",
            "Step  2300 : 621.26 ms/batch | loss  3.21\n",
            "Step  2350 : 626.79 ms/batch | loss  3.31\n",
            "Step  2400 : 624.94 ms/batch | loss  3.19\n",
            "Step  2450 : 628.93 ms/batch | loss  2.71\n",
            "Step  2500 : 626.23 ms/batch | loss  3.10\n",
            "Step  2550 : 622.12 ms/batch | loss  3.01\n",
            "Step  2600 : 625.87 ms/batch | loss  3.45\n",
            "Step  2650 : 626.99 ms/batch | loss  2.61\n",
            "Step  2700 : 625.32 ms/batch | loss  3.28\n",
            "Step  2750 : 618.51 ms/batch | loss  3.23\n",
            "Step  2800 : 623.62 ms/batch | loss  3.29\n",
            "Step    50 : 592.33 ms/batch | loss  3.06\n",
            "Step   100 : 576.96 ms/batch | loss  3.43\n",
            "Step   150 : 572.49 ms/batch | loss  3.56\n",
            "Step   200 : 568.03 ms/batch | loss  3.43\n",
            "Step   250 : 572.85 ms/batch | loss  3.25\n",
            "Step   300 : 574.06 ms/batch | loss  3.23\n",
            "Step   350 : 570.55 ms/batch | loss  3.28\n",
            "Step   400 : 573.43 ms/batch | loss  3.27\n",
            "Step   450 : 568.06 ms/batch | loss  3.28\n",
            "Step   500 : 566.17 ms/batch | loss  3.57\n",
            "Step   550 : 569.24 ms/batch | loss  3.51\n",
            "Step   600 : 563.16 ms/batch | loss  3.29\n",
            "Epoch: 08\n",
            "\tTrain Loss: 3.112\n",
            "\t Val. Loss: 3.345\n",
            "Model saved!\n",
            "Step    50 : 671.05 ms/batch | loss  3.08\n",
            "Step   100 : 625.59 ms/batch | loss  3.36\n",
            "Step   150 : 622.85 ms/batch | loss  3.22\n",
            "Step   200 : 626.77 ms/batch | loss  3.19\n",
            "Step   250 : 621.53 ms/batch | loss  2.94\n",
            "Step   300 : 623.73 ms/batch | loss  3.16\n",
            "Step   350 : 625.40 ms/batch | loss  3.04\n",
            "Step   400 : 618.53 ms/batch | loss  3.27\n",
            "Step   450 : 629.87 ms/batch | loss  3.08\n",
            "Step   500 : 619.69 ms/batch | loss  2.74\n",
            "Step   550 : 612.81 ms/batch | loss  3.21\n",
            "Step   600 : 622.73 ms/batch | loss  2.40\n",
            "Step   650 : 617.70 ms/batch | loss  3.09\n",
            "Step   700 : 623.33 ms/batch | loss  3.16\n",
            "Step   750 : 621.67 ms/batch | loss  3.20\n",
            "Step   800 : 619.70 ms/batch | loss  3.43\n",
            "Step   850 : 625.58 ms/batch | loss  2.93\n",
            "Step   900 : 621.38 ms/batch | loss  2.20\n",
            "Step   950 : 624.17 ms/batch | loss  3.20\n",
            "Step  1000 : 622.68 ms/batch | loss  2.87\n",
            "Step  1050 : 618.01 ms/batch | loss  3.16\n",
            "Step  1100 : 622.38 ms/batch | loss  3.07\n",
            "Step  1150 : 620.69 ms/batch | loss  3.18\n",
            "Step  1200 : 619.56 ms/batch | loss  3.22\n",
            "Step  1250 : 619.20 ms/batch | loss  3.07\n",
            "Step  1300 : 622.45 ms/batch | loss  3.34\n",
            "Step  1350 : 622.04 ms/batch | loss  3.22\n",
            "Step  1400 : 617.21 ms/batch | loss  2.95\n",
            "Step  1450 : 620.22 ms/batch | loss  2.74\n",
            "Step  1500 : 625.96 ms/batch | loss  2.98\n",
            "Step  1550 : 609.65 ms/batch | loss  3.28\n",
            "Step  1600 : 618.73 ms/batch | loss  2.88\n",
            "Step  1650 : 613.41 ms/batch | loss  3.20\n",
            "Step  1700 : 622.81 ms/batch | loss  3.21\n",
            "Step  1750 : 628.24 ms/batch | loss  3.25\n",
            "Step  1800 : 627.27 ms/batch | loss  3.18\n",
            "Step  1850 : 618.29 ms/batch | loss  2.99\n",
            "Step  1900 : 624.05 ms/batch | loss  3.37\n",
            "Step  1950 : 625.38 ms/batch | loss  3.28\n",
            "Step  2000 : 625.46 ms/batch | loss  3.05\n",
            "Step  2050 : 630.03 ms/batch | loss  3.18\n",
            "Step  2100 : 627.22 ms/batch | loss  3.07\n",
            "Step  2150 : 627.30 ms/batch | loss  2.97\n",
            "Step  2200 : 625.82 ms/batch | loss  2.92\n",
            "Step  2250 : 622.96 ms/batch | loss  3.42\n",
            "Step  2300 : 621.26 ms/batch | loss  3.26\n",
            "Step  2350 : 621.60 ms/batch | loss  3.04\n",
            "Step  2400 : 622.99 ms/batch | loss  2.88\n",
            "Step  2450 : 622.60 ms/batch | loss  3.18\n",
            "Step  2500 : 618.66 ms/batch | loss  3.19\n",
            "Step  2550 : 620.69 ms/batch | loss  2.90\n",
            "Step  2600 : 624.03 ms/batch | loss  3.22\n",
            "Step  2650 : 621.14 ms/batch | loss  3.10\n",
            "Step  2700 : 618.94 ms/batch | loss  3.03\n",
            "Step  2750 : 615.29 ms/batch | loss  2.78\n",
            "Step  2800 : 618.90 ms/batch | loss  3.29\n",
            "Step    50 : 597.61 ms/batch | loss  3.44\n",
            "Step   100 : 568.40 ms/batch | loss  3.32\n",
            "Step   150 : 575.47 ms/batch | loss  3.40\n",
            "Step   200 : 567.32 ms/batch | loss  3.08\n",
            "Step   250 : 571.52 ms/batch | loss  3.13\n",
            "Step   300 : 565.52 ms/batch | loss  3.50\n",
            "Step   350 : 573.03 ms/batch | loss  3.28\n",
            "Step   400 : 565.54 ms/batch | loss  3.15\n",
            "Step   450 : 567.92 ms/batch | loss  3.60\n",
            "Step   500 : 570.89 ms/batch | loss  3.39\n",
            "Step   550 : 565.42 ms/batch | loss  2.18\n",
            "Step   600 : 571.36 ms/batch | loss  3.08\n",
            "Epoch: 09\n",
            "\tTrain Loss: 3.086\n",
            "\t Val. Loss: 3.301\n",
            "Model saved!\n",
            "Step    50 : 666.45 ms/batch | loss  3.31\n",
            "Step   100 : 625.90 ms/batch | loss  2.84\n",
            "Step   150 : 619.13 ms/batch | loss  2.89\n",
            "Step   200 : 615.94 ms/batch | loss  3.17\n",
            "Step   250 : 619.16 ms/batch | loss  2.87\n",
            "Step   300 : 607.69 ms/batch | loss  2.87\n",
            "Step   350 : 622.06 ms/batch | loss  3.17\n",
            "Step   400 : 620.19 ms/batch | loss  3.09\n",
            "Step   450 : 628.22 ms/batch | loss  3.00\n",
            "Step   500 : 615.30 ms/batch | loss  3.02\n",
            "Step   550 : 616.83 ms/batch | loss  3.41\n",
            "Step   600 : 624.93 ms/batch | loss  3.02\n",
            "Step   650 : 622.82 ms/batch | loss  3.13\n",
            "Step   700 : 621.93 ms/batch | loss  3.17\n",
            "Step   750 : 618.22 ms/batch | loss  2.98\n",
            "Step   800 : 625.86 ms/batch | loss  3.12\n",
            "Step   850 : 624.77 ms/batch | loss  3.00\n",
            "Step   900 : 622.85 ms/batch | loss  3.17\n",
            "Step   950 : 625.44 ms/batch | loss  3.05\n",
            "Step  1000 : 623.43 ms/batch | loss  3.09\n",
            "Step  1050 : 616.32 ms/batch | loss  3.15\n",
            "Step  1100 : 624.21 ms/batch | loss  3.23\n",
            "Step  1150 : 616.33 ms/batch | loss  3.17\n",
            "Step  1200 : 619.46 ms/batch | loss  2.94\n",
            "Step  1250 : 620.13 ms/batch | loss  2.88\n",
            "Step  1300 : 611.70 ms/batch | loss  3.01\n",
            "Step  1350 : 622.21 ms/batch | loss  2.99\n",
            "Step  1400 : 621.49 ms/batch | loss  2.93\n",
            "Step  1450 : 617.19 ms/batch | loss  3.18\n",
            "Step  1500 : 624.83 ms/batch | loss  3.02\n",
            "Step  1550 : 621.51 ms/batch | loss  3.11\n",
            "Step  1600 : 626.15 ms/batch | loss  3.06\n",
            "Step  1650 : 615.33 ms/batch | loss  2.91\n",
            "Step  1700 : 619.69 ms/batch | loss  3.01\n",
            "Step  1750 : 629.18 ms/batch | loss  3.18\n",
            "Step  1800 : 612.21 ms/batch | loss  3.22\n",
            "Step  1850 : 622.79 ms/batch | loss  3.08\n",
            "Step  1900 : 625.07 ms/batch | loss  2.92\n",
            "Step  1950 : 621.63 ms/batch | loss  3.21\n",
            "Step  2000 : 617.38 ms/batch | loss  3.18\n",
            "Step  2050 : 624.84 ms/batch | loss  3.05\n",
            "Step  2100 : 618.13 ms/batch | loss  2.99\n",
            "Step  2150 : 621.67 ms/batch | loss  3.00\n",
            "Step  2200 : 626.38 ms/batch | loss  3.38\n",
            "Step  2250 : 619.80 ms/batch | loss  2.86\n",
            "Step  2300 : 628.28 ms/batch | loss  3.09\n",
            "Step  2350 : 628.19 ms/batch | loss  3.21\n",
            "Step  2400 : 621.70 ms/batch | loss  3.00\n",
            "Step  2450 : 624.25 ms/batch | loss  3.16\n",
            "Step  2500 : 622.50 ms/batch | loss  3.40\n",
            "Step  2550 : 614.89 ms/batch | loss  3.16\n",
            "Step  2600 : 619.27 ms/batch | loss  3.19\n",
            "Step  2650 : 616.83 ms/batch | loss  3.26\n",
            "Step  2700 : 617.47 ms/batch | loss  2.63\n",
            "Step  2750 : 625.01 ms/batch | loss  3.07\n",
            "Step  2800 : 621.38 ms/batch | loss  2.75\n",
            "Step    50 : 581.19 ms/batch | loss  3.52\n",
            "Step   100 : 567.15 ms/batch | loss  3.53\n",
            "Step   150 : 576.88 ms/batch | loss  3.34\n",
            "Step   200 : 564.44 ms/batch | loss  3.47\n",
            "Step   250 : 573.10 ms/batch | loss  3.62\n",
            "Step   300 : 564.11 ms/batch | loss  3.44\n",
            "Step   350 : 570.38 ms/batch | loss  3.65\n",
            "Step   400 : 563.45 ms/batch | loss  3.71\n",
            "Step   450 : 576.85 ms/batch | loss  3.58\n",
            "Step   500 : 566.48 ms/batch | loss  3.71\n",
            "Step   550 : 563.07 ms/batch | loss  2.78\n",
            "Step   600 : 556.89 ms/batch | loss  3.37\n",
            "Epoch: 10\n",
            "\tTrain Loss: 3.063\n",
            "\t Val. Loss: 3.380\n",
            "Model saved!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}