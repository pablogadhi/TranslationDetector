{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python38264bittranslationdetectorhiqwxbpzvenv4b85a69a239941bfb36f97ba6eeac7ae",
      "display_name": "Python 3.8.2 64-bit ('TranslationDetector-hIqwxbpz': venv)"
    },
    "colab": {
      "name": "sandbox.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pablogadhi/TranslationDetector/blob/master/sandbox.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uG8TzpWkX1nO",
        "colab_type": "code",
        "outputId": "e6c77532-0576-487d-a463-8bcacd4be15f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!git clone https://github.com/pablogadhi/TranslationDetector\n",
        "!python -m spacy download en\n",
        "!python -m spacy download es\n",
        "%cd TranslationDetector\n",
        "!pip install --upgrade torch torchtext"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'TranslationDetector'...\n",
            "remote: Enumerating objects: 64, done.\u001b[K\n",
            "remote: Counting objects: 100% (64/64), done.\u001b[K\n",
            "remote: Compressing objects: 100% (45/45), done.\u001b[K\n",
            "remote: Total 64 (delta 31), reused 44 (delta 18), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (64/64), done.\n",
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.6.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (47.1.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n",
            "Requirement already satisfied: es_core_news_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-2.2.5/es_core_news_sm-2.2.5.tar.gz#egg=es_core_news_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from es_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (47.1.1)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (0.6.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->es_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->es_core_news_sm==2.2.5) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->es_core_news_sm==2.2.5) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->es_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->es_core_news_sm==2.2.5) (1.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->es_core_news_sm==2.2.5) (3.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('es_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/es_core_news_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/es\n",
            "You can now load the model via spacy.load('es')\n",
            "/content/TranslationDetector/TranslationDetector\n",
            "Requirement already up-to-date: torch in /usr/local/lib/python3.6/dist-packages (1.5.0+cu101)\n",
            "Requirement already up-to-date: torchtext in /usr/local/lib/python3.6/dist-packages (0.6.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from torchtext) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from torchtext) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: sentencepiece in /usr/local/lib/python3.6/dist-packages (from torchtext) (0.1.91)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2.9)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2020.4.5.1)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0FtCASL4cnB",
        "colab_type": "code",
        "outputId": "addad896-3c99-4878-b29d-22292fb86af2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PE1l5dNzZ_64",
        "colab_type": "code",
        "outputId": "770314c1-f112-4c66-a4f1-42ab2e6d2449",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!git pull"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-xIrWVKXwyc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from translation.train import train_model\n",
        "from translation.data_loader import load_data, make_iters\n",
        "from translation.transformer import Transformer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vi40z2LrXwym",
        "colab_type": "code",
        "outputId": "38ad26e9-01da-4b48-c467-82fa504925d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CLkwuwc5VBQ",
        "colab_type": "code",
        "outputId": "b362840b-d5c8-49f8-e1f4-1e487676ff59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Jun 10 19:47:22 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P0    26W / 250W |     10MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUn26OeiXwyw",
        "colab_type": "text"
      },
      "source": [
        "### Load data and create the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtOFq2VT4tyK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_DIR='/content/drive/My Drive/NLP/data/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ixf7Ff4_Xwyx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "aef14d70-a1c4-4b86-ed41-1dbaaf8d4994"
      },
      "source": [
        "SRC, TGT, train, valid, test = load_data(\n",
        "        DATA_DIR + \"en-es-0_\", \"es.txt\", \"en.txt\", DATA_DIR + \"TGT_Field.pt\", DATA_DIR + \"SRC_Field.pt\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "Data loaded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_c_45HZAXwy4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_itr, valid_itr, test_itr = make_iters(\n",
        "        train, valid, test, device, batch_size=4000)\n",
        "model = Transformer(len(SRC.vocab), len(TGT.vocab)).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbNzEw9xXwzJ",
        "colab_type": "code",
        "outputId": "43f50144-9af4-4dc0-aebc-93ae4cedfb20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(SRC.vocab.itos)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLQ7ImaaXwzN",
        "colab_type": "text"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SF1CDRaYXwzO",
        "colab_type": "code",
        "outputId": "e1f73737-896e-48bf-b10f-0a7c80081323",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_model(model, train_itr, valid_itr, SRC, TGT, device, 10, save_at=1, checkpoint_f=DATA_DIR + \"checkpoint.pt\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step    50 : 397.45 ms/batch | loss  8.05\n",
            "Step   100 : 346.24 ms/batch | loss  6.98\n",
            "Step   150 : 342.45 ms/batch | loss  5.86\n",
            "Step   200 : 347.34 ms/batch | loss  5.46\n",
            "Step   250 : 350.40 ms/batch | loss  4.78\n",
            "Step   300 : 342.61 ms/batch | loss  5.15\n",
            "Step   350 : 349.37 ms/batch | loss  4.62\n",
            "Step   400 : 342.31 ms/batch | loss  4.85\n",
            "Step   450 : 343.95 ms/batch | loss  4.37\n",
            "Step   500 : 344.30 ms/batch | loss  4.88\n",
            "Step   550 : 342.46 ms/batch | loss  3.84\n",
            "Step   600 : 343.19 ms/batch | loss  4.56\n",
            "Step   650 : 345.60 ms/batch | loss  4.36\n",
            "Step   700 : 340.68 ms/batch | loss  4.46\n",
            "Step   750 : 342.59 ms/batch | loss  4.46\n",
            "Step   800 : 346.79 ms/batch | loss  4.16\n",
            "Step   850 : 346.28 ms/batch | loss  4.44\n",
            "Step   900 : 339.05 ms/batch | loss  3.91\n",
            "Step   950 : 346.03 ms/batch | loss  4.00\n",
            "Step  1000 : 339.11 ms/batch | loss  3.90\n",
            "Step  1050 : 347.14 ms/batch | loss  4.34\n",
            "Step  1100 : 346.12 ms/batch | loss  4.13\n",
            "Step  1150 : 339.63 ms/batch | loss  4.06\n",
            "Step  1200 : 342.82 ms/batch | loss  3.42\n",
            "Step  1250 : 344.27 ms/batch | loss  3.91\n",
            "Step  1300 : 347.16 ms/batch | loss  4.06\n",
            "Step  1350 : 343.63 ms/batch | loss  4.12\n",
            "Step  1400 : 339.83 ms/batch | loss  3.96\n",
            "Step  1450 : 342.74 ms/batch | loss  3.90\n",
            "Step  1500 : 343.14 ms/batch | loss  4.44\n",
            "Step  1550 : 341.98 ms/batch | loss  4.14\n",
            "Step  1600 : 342.47 ms/batch | loss  4.07\n",
            "Step  1650 : 346.80 ms/batch | loss  3.83\n",
            "Step  1700 : 338.32 ms/batch | loss  4.37\n",
            "Step  1750 : 349.34 ms/batch | loss  4.20\n",
            "Step  1800 : 344.67 ms/batch | loss  4.07\n",
            "Step  1850 : 342.68 ms/batch | loss  4.03\n",
            "Step  1900 : 345.11 ms/batch | loss  3.81\n",
            "Step  1950 : 341.42 ms/batch | loss  4.13\n",
            "Step  2000 : 339.45 ms/batch | loss  3.69\n",
            "Step  2050 : 342.38 ms/batch | loss  4.06\n",
            "Step  2100 : 342.24 ms/batch | loss  4.13\n",
            "Step  2150 : 341.90 ms/batch | loss  3.58\n",
            "Step  2200 : 342.46 ms/batch | loss  3.90\n",
            "Step  2250 : 347.05 ms/batch | loss  3.21\n",
            "Step  2300 : 346.08 ms/batch | loss  3.76\n",
            "Step  2350 : 342.47 ms/batch | loss  4.25\n",
            "Step  2400 : 342.20 ms/batch | loss  3.75\n",
            "Step  2450 : 343.61 ms/batch | loss  3.86\n",
            "Step  2500 : 341.23 ms/batch | loss  3.36\n",
            "Step  2550 : 340.75 ms/batch | loss  3.73\n",
            "Step  2600 : 344.07 ms/batch | loss  3.92\n",
            "Step  2650 : 342.79 ms/batch | loss  4.05\n",
            "Step  2700 : 345.88 ms/batch | loss  3.87\n",
            "Step  2750 : 343.75 ms/batch | loss  3.01\n",
            "Step    50 : 310.52 ms/batch | loss  3.96\n",
            "Step   100 : 295.92 ms/batch | loss  3.98\n",
            "Step   150 : 297.49 ms/batch | loss  3.82\n",
            "Step   200 : 303.00 ms/batch | loss  4.04\n",
            "Step   250 : 299.35 ms/batch | loss  3.70\n",
            "Step   300 : 301.86 ms/batch | loss  3.60\n",
            "Step   350 : 300.57 ms/batch | loss  3.56\n",
            "Step   400 : 295.79 ms/batch | loss  3.80\n",
            "Step   450 : 299.16 ms/batch | loss  3.88\n",
            "Step   500 : 299.60 ms/batch | loss  3.75\n",
            "Step   550 : 298.13 ms/batch | loss  3.19\n",
            "Step   600 : 294.02 ms/batch | loss  3.90\n",
            "Epoch: 01\n",
            "\tTrain Loss: 4.351\n",
            "\t Val. Loss: 3.737\n",
            "Model saved!\n",
            "Step    50 : 399.73 ms/batch | loss  3.48\n",
            "Step   100 : 345.27 ms/batch | loss  3.77\n",
            "Step   150 : 346.61 ms/batch | loss  3.55\n",
            "Step   200 : 345.57 ms/batch | loss  3.44\n",
            "Step   250 : 338.24 ms/batch | loss  3.81\n",
            "Step   300 : 339.71 ms/batch | loss  3.79\n",
            "Step   350 : 344.05 ms/batch | loss  3.68\n",
            "Step   400 : 340.01 ms/batch | loss  3.57\n",
            "Step   450 : 347.87 ms/batch | loss  3.85\n",
            "Step   500 : 346.46 ms/batch | loss  3.99\n",
            "Step   550 : 343.64 ms/batch | loss  3.53\n",
            "Step   600 : 344.32 ms/batch | loss  4.07\n",
            "Step   650 : 346.51 ms/batch | loss  3.88\n",
            "Step   700 : 344.04 ms/batch | loss  3.85\n",
            "Step   750 : 340.59 ms/batch | loss  3.76\n",
            "Step   800 : 349.13 ms/batch | loss  3.93\n",
            "Step   850 : 341.62 ms/batch | loss  3.77\n",
            "Step   900 : 347.09 ms/batch | loss  3.71\n",
            "Step   950 : 344.32 ms/batch | loss  3.44\n",
            "Step  1000 : 337.11 ms/batch | loss  3.90\n",
            "Step  1050 : 344.58 ms/batch | loss  3.79\n",
            "Step  1100 : 347.29 ms/batch | loss  3.66\n",
            "Step  1150 : 341.41 ms/batch | loss  3.80\n",
            "Step  1200 : 341.52 ms/batch | loss  3.54\n",
            "Step  1250 : 342.76 ms/batch | loss  3.61\n",
            "Step  1300 : 341.27 ms/batch | loss  3.65\n",
            "Step  1350 : 334.80 ms/batch | loss  3.90\n",
            "Step  1400 : 347.08 ms/batch | loss  3.19\n",
            "Step  1450 : 335.50 ms/batch | loss  3.61\n",
            "Step  1500 : 343.38 ms/batch | loss  3.68\n",
            "Step  1550 : 344.43 ms/batch | loss  3.61\n",
            "Step  1600 : 342.70 ms/batch | loss  3.43\n",
            "Step  1650 : 346.66 ms/batch | loss  3.73\n",
            "Step  1700 : 342.37 ms/batch | loss  3.71\n",
            "Step  1750 : 345.20 ms/batch | loss  3.61\n",
            "Step  1800 : 347.10 ms/batch | loss  3.91\n",
            "Step  1850 : 346.12 ms/batch | loss  3.56\n",
            "Step  1900 : 342.89 ms/batch | loss  3.61\n",
            "Step  1950 : 342.76 ms/batch | loss  3.18\n",
            "Step  2000 : 343.38 ms/batch | loss  3.76\n",
            "Step  2050 : 348.08 ms/batch | loss  3.52\n",
            "Step  2100 : 346.36 ms/batch | loss  3.59\n",
            "Step  2150 : 341.12 ms/batch | loss  3.02\n",
            "Step  2200 : 340.19 ms/batch | loss  3.64\n",
            "Step  2250 : 340.55 ms/batch | loss  3.68\n",
            "Step  2300 : 342.53 ms/batch | loss  3.87\n",
            "Step  2350 : 344.31 ms/batch | loss  3.74\n",
            "Step  2400 : 348.31 ms/batch | loss  3.57\n",
            "Step  2450 : 342.52 ms/batch | loss  3.44\n",
            "Step  2500 : 341.33 ms/batch | loss  3.46\n",
            "Step  2550 : 344.00 ms/batch | loss  3.56\n",
            "Step  2600 : 342.65 ms/batch | loss  3.79\n",
            "Step  2650 : 342.51 ms/batch | loss  3.54\n",
            "Step  2700 : 344.22 ms/batch | loss  3.46\n",
            "Step  2750 : 339.43 ms/batch | loss  3.63\n",
            "Step    50 : 313.52 ms/batch | loss  3.55\n",
            "Step   100 : 301.82 ms/batch | loss  3.74\n",
            "Step   150 : 300.64 ms/batch | loss  3.76\n",
            "Step   200 : 299.67 ms/batch | loss  3.80\n",
            "Step   250 : 297.02 ms/batch | loss  3.61\n",
            "Step   300 : 302.65 ms/batch | loss  3.64\n",
            "Step   350 : 302.35 ms/batch | loss  3.44\n",
            "Step   400 : 297.93 ms/batch | loss  3.45\n",
            "Step   450 : 294.55 ms/batch | loss  3.68\n",
            "Step   500 : 295.63 ms/batch | loss  3.86\n",
            "Step   550 : 292.19 ms/batch | loss  3.71\n",
            "Step   600 : 299.80 ms/batch | loss  3.80\n",
            "Epoch: 02\n",
            "\tTrain Loss: 3.603\n",
            "\t Val. Loss: 3.602\n",
            "Model saved!\n",
            "Step    50 : 400.78 ms/batch | loss  3.61\n",
            "Step   100 : 349.75 ms/batch | loss  2.95\n",
            "Step   150 : 350.02 ms/batch | loss  3.42\n",
            "Step   200 : 339.43 ms/batch | loss  3.55\n",
            "Step   250 : 341.05 ms/batch | loss  3.21\n",
            "Step   300 : 341.22 ms/batch | loss  3.40\n",
            "Step   350 : 341.40 ms/batch | loss  3.37\n",
            "Step   400 : 347.28 ms/batch | loss  3.18\n",
            "Step   450 : 345.38 ms/batch | loss  3.74\n",
            "Step   500 : 339.22 ms/batch | loss  3.43\n",
            "Step   550 : 345.83 ms/batch | loss  3.57\n",
            "Step   600 : 341.66 ms/batch | loss  3.16\n",
            "Step   650 : 342.43 ms/batch | loss  3.71\n",
            "Step   700 : 344.08 ms/batch | loss  3.66\n",
            "Step   750 : 341.14 ms/batch | loss  3.40\n",
            "Step   800 : 347.09 ms/batch | loss  3.51\n",
            "Step   850 : 347.52 ms/batch | loss  3.48\n",
            "Step   900 : 342.23 ms/batch | loss  3.48\n",
            "Step   950 : 343.22 ms/batch | loss  3.33\n",
            "Step  1000 : 342.24 ms/batch | loss  3.38\n",
            "Step  1050 : 344.28 ms/batch | loss  3.00\n",
            "Step  1100 : 342.13 ms/batch | loss  3.40\n",
            "Step  1150 : 347.48 ms/batch | loss  3.56\n",
            "Step  1200 : 341.04 ms/batch | loss  3.35\n",
            "Step  1250 : 343.47 ms/batch | loss  3.32\n",
            "Step  1300 : 343.27 ms/batch | loss  3.33\n",
            "Step  1350 : 343.12 ms/batch | loss  3.42\n",
            "Step  1400 : 343.86 ms/batch | loss  3.50\n",
            "Step  1450 : 343.82 ms/batch | loss  3.55\n",
            "Step  1500 : 345.28 ms/batch | loss  3.32\n",
            "Step  1550 : 342.72 ms/batch | loss  3.62\n",
            "Step  1600 : 344.19 ms/batch | loss  3.04\n",
            "Step  1650 : 348.07 ms/batch | loss  3.19\n",
            "Step  1700 : 346.04 ms/batch | loss  3.28\n",
            "Step  1750 : 344.96 ms/batch | loss  3.52\n",
            "Step  1800 : 350.62 ms/batch | loss  3.56\n",
            "Step  1850 : 344.79 ms/batch | loss  3.44\n",
            "Step  1900 : 347.06 ms/batch | loss  3.42\n",
            "Step  1950 : 349.75 ms/batch | loss  3.41\n",
            "Step  2000 : 347.91 ms/batch | loss  3.35\n",
            "Step  2050 : 344.02 ms/batch | loss  3.32\n",
            "Step  2100 : 342.21 ms/batch | loss  3.38\n",
            "Step  2150 : 343.27 ms/batch | loss  3.85\n",
            "Step  2200 : 343.83 ms/batch | loss  3.25\n",
            "Step  2250 : 342.32 ms/batch | loss  2.99\n",
            "Step  2300 : 346.67 ms/batch | loss  3.47\n",
            "Step  2350 : 343.76 ms/batch | loss  3.48\n",
            "Step  2400 : 344.46 ms/batch | loss  3.48\n",
            "Step  2450 : 344.42 ms/batch | loss  3.63\n",
            "Step  2500 : 344.76 ms/batch | loss  3.43\n",
            "Step  2550 : 339.66 ms/batch | loss  3.66\n",
            "Step  2600 : 348.46 ms/batch | loss  3.26\n",
            "Step  2650 : 348.88 ms/batch | loss  2.91\n",
            "Step  2700 : 343.99 ms/batch | loss  3.40\n",
            "Step  2750 : 342.89 ms/batch | loss  3.26\n",
            "Step    50 : 308.00 ms/batch | loss  3.48\n",
            "Step   100 : 303.71 ms/batch | loss  4.65\n",
            "Step   150 : 295.21 ms/batch | loss  3.50\n",
            "Step   200 : 300.76 ms/batch | loss  3.20\n",
            "Step   250 : 298.22 ms/batch | loss  4.60\n",
            "Step   300 : 299.96 ms/batch | loss  3.99\n",
            "Step   350 : 298.02 ms/batch | loss  3.96\n",
            "Step   400 : 298.53 ms/batch | loss  4.03\n",
            "Step   450 : 299.28 ms/batch | loss  3.90\n",
            "Step   500 : 296.92 ms/batch | loss  3.84\n",
            "Step   550 : 300.95 ms/batch | loss  4.75\n",
            "Step   600 : 300.52 ms/batch | loss  4.02\n",
            "Epoch: 03\n",
            "\tTrain Loss: 3.396\n",
            "\t Val. Loss: 3.898\n",
            "Model saved!\n",
            "Step    50 : 403.41 ms/batch | loss  3.54\n",
            "Step   100 : 348.96 ms/batch | loss  3.11\n",
            "Step   150 : 347.24 ms/batch | loss  3.82\n",
            "Step   200 : 341.79 ms/batch | loss  3.30\n",
            "Step   250 : 341.40 ms/batch | loss  3.38\n",
            "Step   300 : 344.09 ms/batch | loss  3.46\n",
            "Step   350 : 342.42 ms/batch | loss  3.79\n",
            "Step   400 : 338.34 ms/batch | loss  3.15\n",
            "Step   450 : 344.37 ms/batch | loss  3.27\n",
            "Step   500 : 347.95 ms/batch | loss  3.19\n",
            "Step   550 : 341.52 ms/batch | loss  3.15\n",
            "Step   600 : 343.62 ms/batch | loss  3.31\n",
            "Step   650 : 343.83 ms/batch | loss  3.41\n",
            "Step   700 : 346.23 ms/batch | loss  3.24\n",
            "Step   750 : 351.43 ms/batch | loss  3.22\n",
            "Step   800 : 342.42 ms/batch | loss  3.37\n",
            "Step   850 : 343.66 ms/batch | loss  3.29\n",
            "Step   900 : 341.71 ms/batch | loss  3.37\n",
            "Step   950 : 350.18 ms/batch | loss  3.26\n",
            "Step  1000 : 344.55 ms/batch | loss  3.39\n",
            "Step  1050 : 346.76 ms/batch | loss  3.72\n",
            "Step  1100 : 348.89 ms/batch | loss  3.27\n",
            "Step  1150 : 345.22 ms/batch | loss  2.67\n",
            "Step  1200 : 348.37 ms/batch | loss  3.32\n",
            "Step  1250 : 346.73 ms/batch | loss  3.42\n",
            "Step  1300 : 345.48 ms/batch | loss  2.98\n",
            "Step  1350 : 346.31 ms/batch | loss  3.39\n",
            "Step  1400 : 345.77 ms/batch | loss  3.35\n",
            "Step  1450 : 340.44 ms/batch | loss  3.30\n",
            "Step  1500 : 349.00 ms/batch | loss  3.24\n",
            "Step  1550 : 344.14 ms/batch | loss  3.61\n",
            "Step  1600 : 348.10 ms/batch | loss  3.23\n",
            "Step  1650 : 345.19 ms/batch | loss  3.12\n",
            "Step  1700 : 345.53 ms/batch | loss  3.42\n",
            "Step  1750 : 346.01 ms/batch | loss  3.10\n",
            "Step  1800 : 345.41 ms/batch | loss  3.30\n",
            "Step  1850 : 347.18 ms/batch | loss  3.41\n",
            "Step  1900 : 341.61 ms/batch | loss  3.35\n",
            "Step  1950 : 342.25 ms/batch | loss  3.38\n",
            "Step  2000 : 343.30 ms/batch | loss  3.53\n",
            "Step  2050 : 342.78 ms/batch | loss  2.89\n",
            "Step  2100 : 347.16 ms/batch | loss  2.87\n",
            "Step  2150 : 343.70 ms/batch | loss  3.11\n",
            "Step  2200 : 344.58 ms/batch | loss  3.60\n",
            "Step  2250 : 344.18 ms/batch | loss  3.34\n",
            "Step  2300 : 345.57 ms/batch | loss  3.30\n",
            "Step  2350 : 347.99 ms/batch | loss  3.16\n",
            "Step  2400 : 345.07 ms/batch | loss  3.36\n",
            "Step  2450 : 344.28 ms/batch | loss  3.39\n",
            "Step  2500 : 347.55 ms/batch | loss  3.19\n",
            "Step  2550 : 343.21 ms/batch | loss  3.05\n",
            "Step  2600 : 346.26 ms/batch | loss  3.42\n",
            "Step  2650 : 343.26 ms/batch | loss  3.07\n",
            "Step  2700 : 344.41 ms/batch | loss  3.19\n",
            "Step  2750 : 338.11 ms/batch | loss  3.28\n",
            "Step    50 : 316.29 ms/batch | loss  5.33\n",
            "Step   100 : 304.79 ms/batch | loss  4.22\n",
            "Step   150 : 295.45 ms/batch | loss  4.21\n",
            "Step   200 : 298.39 ms/batch | loss  5.72\n",
            "Step   250 : 295.09 ms/batch | loss  5.23\n",
            "Step   300 : 301.22 ms/batch | loss  3.11\n",
            "Step   350 : 300.28 ms/batch | loss  4.80\n",
            "Step   400 : 303.05 ms/batch | loss  3.85\n",
            "Step   450 : 297.40 ms/batch | loss  6.18\n",
            "Step   500 : 294.86 ms/batch | loss  3.76\n",
            "Step   550 : 300.65 ms/batch | loss  6.19\n",
            "Step   600 : 298.43 ms/batch | loss  2.69\n",
            "Epoch: 04\n",
            "\tTrain Loss: 3.289\n",
            "\t Val. Loss: 4.948\n",
            "Model saved!\n",
            "Step    50 : 402.74 ms/batch | loss  3.43\n",
            "Step   100 : 342.89 ms/batch | loss  3.39\n",
            "Step   150 : 350.81 ms/batch | loss  3.29\n",
            "Step   200 : 346.90 ms/batch | loss  3.29\n",
            "Step   250 : 340.63 ms/batch | loss  3.28\n",
            "Step   300 : 349.38 ms/batch | loss  3.10\n",
            "Step   350 : 344.61 ms/batch | loss  3.21\n",
            "Step   400 : 345.63 ms/batch | loss  3.06\n",
            "Step   450 : 345.79 ms/batch | loss  3.18\n",
            "Step   500 : 340.58 ms/batch | loss  3.14\n",
            "Step   550 : 343.97 ms/batch | loss  3.20\n",
            "Step   600 : 343.29 ms/batch | loss  3.29\n",
            "Step   650 : 347.51 ms/batch | loss  3.11\n",
            "Step   700 : 344.15 ms/batch | loss  3.25\n",
            "Step   750 : 344.09 ms/batch | loss  3.22\n",
            "Step   800 : 340.65 ms/batch | loss  3.35\n",
            "Step   850 : 340.70 ms/batch | loss  3.19\n",
            "Step   900 : 346.40 ms/batch | loss  3.26\n",
            "Step   950 : 342.90 ms/batch | loss  3.26\n",
            "Step  1000 : 344.06 ms/batch | loss  2.99\n",
            "Step  1050 : 344.17 ms/batch | loss  3.35\n",
            "Step  1100 : 347.40 ms/batch | loss  3.37\n",
            "Step  1150 : 342.80 ms/batch | loss  3.27\n",
            "Step  1200 : 346.70 ms/batch | loss  3.21\n",
            "Step  1250 : 346.15 ms/batch | loss  3.04\n",
            "Step  1300 : 348.22 ms/batch | loss  3.24\n",
            "Step  1350 : 342.14 ms/batch | loss  2.92\n",
            "Step  1400 : 341.96 ms/batch | loss  3.27\n",
            "Step  1450 : 350.63 ms/batch | loss  3.21\n",
            "Step  1500 : 343.27 ms/batch | loss  3.12\n",
            "Step  1550 : 343.34 ms/batch | loss  3.26\n",
            "Step  1600 : 341.88 ms/batch | loss  3.18\n",
            "Step  1650 : 345.18 ms/batch | loss  3.46\n",
            "Step  1700 : 345.19 ms/batch | loss  3.33\n",
            "Step  1750 : 343.64 ms/batch | loss  3.25\n",
            "Step  1800 : 342.43 ms/batch | loss  3.10\n",
            "Step  1850 : 340.79 ms/batch | loss  3.24\n",
            "Step  1900 : 344.93 ms/batch | loss  3.16\n",
            "Step  1950 : 346.44 ms/batch | loss  3.32\n",
            "Step  2000 : 345.04 ms/batch | loss  3.36\n",
            "Step  2050 : 343.43 ms/batch | loss  3.27\n",
            "Step  2100 : 347.25 ms/batch | loss  3.16\n",
            "Step  2150 : 344.59 ms/batch | loss  3.12\n",
            "Step  2200 : 348.44 ms/batch | loss  2.96\n",
            "Step  2250 : 340.27 ms/batch | loss  3.19\n",
            "Step  2300 : 344.71 ms/batch | loss  2.49\n",
            "Step  2350 : 346.03 ms/batch | loss  3.22\n",
            "Step  2400 : 343.88 ms/batch | loss  2.50\n",
            "Step  2450 : 344.72 ms/batch | loss  3.47\n",
            "Step  2500 : 350.72 ms/batch | loss  3.18\n",
            "Step  2550 : 343.47 ms/batch | loss  3.22\n",
            "Step  2600 : 343.94 ms/batch | loss  3.24\n",
            "Step  2650 : 344.07 ms/batch | loss  3.06\n",
            "Step  2700 : 344.82 ms/batch | loss  3.16\n",
            "Step  2750 : 347.64 ms/batch | loss  3.00\n",
            "Step    50 : 316.33 ms/batch | loss  3.44\n",
            "Step   100 : 293.39 ms/batch | loss  3.60\n",
            "Step   150 : 294.15 ms/batch | loss  3.52\n",
            "Step   200 : 297.22 ms/batch | loss  3.63\n",
            "Step   250 : 300.34 ms/batch | loss  3.90\n",
            "Step   300 : 302.99 ms/batch | loss  3.76\n",
            "Step   350 : 302.54 ms/batch | loss  2.62\n",
            "Step   400 : 286.32 ms/batch | loss  3.61\n",
            "Step   450 : 305.52 ms/batch | loss  3.58\n",
            "Step   500 : 302.31 ms/batch | loss  3.34\n",
            "Step   550 : 301.50 ms/batch | loss  3.76\n",
            "Step   600 : 304.79 ms/batch | loss  3.82\n",
            "Epoch: 05\n",
            "\tTrain Loss: 3.221\n",
            "\t Val. Loss: 3.593\n",
            "Model saved!\n",
            "Step    50 : 402.37 ms/batch | loss  3.34\n",
            "Step   100 : 350.29 ms/batch | loss  3.08\n",
            "Step   150 : 347.03 ms/batch | loss  3.22\n",
            "Step   200 : 342.84 ms/batch | loss  3.48\n",
            "Step   250 : 351.21 ms/batch | loss  3.10\n",
            "Step   300 : 344.90 ms/batch | loss  3.14\n",
            "Step   350 : 338.08 ms/batch | loss  3.18\n",
            "Step   400 : 346.40 ms/batch | loss  3.10\n",
            "Step   450 : 345.37 ms/batch | loss  3.26\n",
            "Step   500 : 345.55 ms/batch | loss  3.23\n",
            "Step   550 : 348.13 ms/batch | loss  3.14\n",
            "Step   600 : 341.48 ms/batch | loss  3.46\n",
            "Step   650 : 345.04 ms/batch | loss  3.11\n",
            "Step   700 : 344.22 ms/batch | loss  3.01\n",
            "Step   750 : 336.62 ms/batch | loss  3.31\n",
            "Step   800 : 348.42 ms/batch | loss  3.02\n",
            "Step   850 : 343.39 ms/batch | loss  3.15\n",
            "Step   900 : 344.72 ms/batch | loss  3.12\n",
            "Step   950 : 352.34 ms/batch | loss  3.24\n",
            "Step  1000 : 345.15 ms/batch | loss  3.29\n",
            "Step  1050 : 345.41 ms/batch | loss  3.36\n",
            "Step  1100 : 342.49 ms/batch | loss  2.98\n",
            "Step  1150 : 347.73 ms/batch | loss  3.13\n",
            "Step  1200 : 345.51 ms/batch | loss  2.85\n",
            "Step  1250 : 348.94 ms/batch | loss  3.00\n",
            "Step  1300 : 348.10 ms/batch | loss  3.00\n",
            "Step  1350 : 345.71 ms/batch | loss  2.98\n",
            "Step  1400 : 341.75 ms/batch | loss  3.46\n",
            "Step  1450 : 343.04 ms/batch | loss  2.65\n",
            "Step  1500 : 347.23 ms/batch | loss  3.19\n",
            "Step  1550 : 347.70 ms/batch | loss  3.12\n",
            "Step  1600 : 346.69 ms/batch | loss  2.78\n",
            "Step  1650 : 342.41 ms/batch | loss  3.13\n",
            "Step  1700 : 345.01 ms/batch | loss  3.08\n",
            "Step  1750 : 346.35 ms/batch | loss  3.14\n",
            "Step  1800 : 346.99 ms/batch | loss  3.13\n",
            "Step  1850 : 343.62 ms/batch | loss  3.17\n",
            "Step  1900 : 343.42 ms/batch | loss  3.15\n",
            "Step  1950 : 345.48 ms/batch | loss  2.97\n",
            "Step  2000 : 344.24 ms/batch | loss  3.16\n",
            "Step  2050 : 343.93 ms/batch | loss  3.22\n",
            "Step  2100 : 346.93 ms/batch | loss  2.99\n",
            "Step  2150 : 343.15 ms/batch | loss  3.17\n",
            "Step  2200 : 344.11 ms/batch | loss  3.63\n",
            "Step  2250 : 341.27 ms/batch | loss  3.04\n",
            "Step  2300 : 346.15 ms/batch | loss  3.18\n",
            "Step  2350 : 344.73 ms/batch | loss  3.19\n",
            "Step  2400 : 346.63 ms/batch | loss  3.36\n",
            "Step  2450 : 351.22 ms/batch | loss  3.20\n",
            "Step  2500 : 343.87 ms/batch | loss  3.40\n",
            "Step  2550 : 344.82 ms/batch | loss  3.23\n",
            "Step  2600 : 345.31 ms/batch | loss  3.16\n",
            "Step  2650 : 341.64 ms/batch | loss  3.10\n",
            "Step  2700 : 344.50 ms/batch | loss  3.11\n",
            "Step  2750 : 342.25 ms/batch | loss  3.19\n",
            "Step    50 : 305.90 ms/batch | loss  3.46\n",
            "Step   100 : 301.34 ms/batch | loss  3.78\n",
            "Step   150 : 302.38 ms/batch | loss  3.42\n",
            "Step   200 : 301.59 ms/batch | loss  3.85\n",
            "Step   250 : 299.16 ms/batch | loss  3.77\n",
            "Step   300 : 299.83 ms/batch | loss  3.95\n",
            "Step   350 : 300.91 ms/batch | loss  3.60\n",
            "Step   400 : 295.78 ms/batch | loss  3.91\n",
            "Step   450 : 302.68 ms/batch | loss  3.89\n",
            "Step   500 : 297.11 ms/batch | loss  3.45\n",
            "Step   550 : 299.64 ms/batch | loss  2.56\n",
            "Step   600 : 296.36 ms/batch | loss  3.54\n",
            "Epoch: 06\n",
            "\tTrain Loss: 3.173\n",
            "\t Val. Loss: 3.631\n",
            "Model saved!\n",
            "Step    50 : 398.47 ms/batch | loss  3.29\n",
            "Step   100 : 340.91 ms/batch | loss  3.19\n",
            "Step   150 : 343.90 ms/batch | loss  3.26\n",
            "Step   200 : 344.94 ms/batch | loss  2.98\n",
            "Step   250 : 342.63 ms/batch | loss  3.27\n",
            "Step   300 : 342.03 ms/batch | loss  3.15\n",
            "Step   350 : 349.78 ms/batch | loss  3.02\n",
            "Step   400 : 343.55 ms/batch | loss  2.95\n",
            "Step   450 : 344.79 ms/batch | loss  3.52\n",
            "Step   500 : 347.26 ms/batch | loss  3.27\n",
            "Step   550 : 347.53 ms/batch | loss  3.01\n",
            "Step   600 : 349.18 ms/batch | loss  3.12\n",
            "Step   650 : 340.06 ms/batch | loss  3.24\n",
            "Step   700 : 340.19 ms/batch | loss  2.94\n",
            "Step   750 : 347.04 ms/batch | loss  3.13\n",
            "Step   800 : 348.37 ms/batch | loss  3.15\n",
            "Step   850 : 344.91 ms/batch | loss  3.31\n",
            "Step   900 : 343.85 ms/batch | loss  3.19\n",
            "Step   950 : 343.49 ms/batch | loss  3.05\n",
            "Step  1000 : 348.90 ms/batch | loss  3.16\n",
            "Step  1050 : 344.17 ms/batch | loss  2.95\n",
            "Step  1100 : 343.50 ms/batch | loss  3.13\n",
            "Step  1150 : 344.55 ms/batch | loss  2.98\n",
            "Step  1200 : 344.12 ms/batch | loss  3.21\n",
            "Step  1250 : 342.68 ms/batch | loss  2.88\n",
            "Step  1300 : 347.07 ms/batch | loss  2.96\n",
            "Step  1350 : 342.42 ms/batch | loss  2.95\n",
            "Step  1400 : 347.19 ms/batch | loss  3.17\n",
            "Step  1450 : 348.08 ms/batch | loss  3.15\n",
            "Step  1500 : 348.51 ms/batch | loss  3.34\n",
            "Step  1550 : 345.98 ms/batch | loss  3.19\n",
            "Step  1600 : 343.50 ms/batch | loss  2.82\n",
            "Step  1650 : 344.92 ms/batch | loss  2.97\n",
            "Step  1700 : 345.88 ms/batch | loss  3.26\n",
            "Step  1750 : 342.61 ms/batch | loss  3.40\n",
            "Step  1800 : 347.74 ms/batch | loss  2.99\n",
            "Step  1850 : 348.00 ms/batch | loss  3.20\n",
            "Step  1900 : 345.09 ms/batch | loss  3.37\n",
            "Step  1950 : 345.26 ms/batch | loss  3.05\n",
            "Step  2000 : 347.09 ms/batch | loss  3.15\n",
            "Step  2050 : 341.32 ms/batch | loss  3.48\n",
            "Step  2100 : 342.44 ms/batch | loss  3.47\n",
            "Step  2150 : 345.12 ms/batch | loss  2.98\n",
            "Step  2200 : 340.47 ms/batch | loss  3.08\n",
            "Step  2250 : 339.43 ms/batch | loss  3.07\n",
            "Step  2300 : 346.10 ms/batch | loss  3.17\n",
            "Step  2350 : 344.10 ms/batch | loss  3.13\n",
            "Step  2400 : 345.48 ms/batch | loss  3.11\n",
            "Step  2450 : 346.13 ms/batch | loss  3.38\n",
            "Step  2500 : 345.86 ms/batch | loss  3.34\n",
            "Step  2550 : 347.39 ms/batch | loss  3.10\n",
            "Step  2600 : 348.62 ms/batch | loss  3.16\n",
            "Step  2650 : 347.78 ms/batch | loss  3.26\n",
            "Step  2700 : 346.39 ms/batch | loss  3.31\n",
            "Step  2750 : 347.18 ms/batch | loss  3.30\n",
            "Step    50 : 317.18 ms/batch | loss  3.62\n",
            "Step   100 : 299.18 ms/batch | loss  3.67\n",
            "Step   150 : 301.39 ms/batch | loss  3.51\n",
            "Step   200 : 292.51 ms/batch | loss  3.87\n",
            "Step   250 : 299.05 ms/batch | loss  3.56\n",
            "Step   300 : 301.83 ms/batch | loss  3.63\n",
            "Step   350 : 302.37 ms/batch | loss  3.72\n",
            "Step   400 : 294.42 ms/batch | loss  3.54\n",
            "Step   450 : 302.67 ms/batch | loss  3.48\n",
            "Step   500 : 301.01 ms/batch | loss  3.55\n",
            "Step   550 : 298.52 ms/batch | loss  4.20\n",
            "Step   600 : 295.56 ms/batch | loss  3.57\n",
            "Epoch: 07\n",
            "\tTrain Loss: 3.133\n",
            "\t Val. Loss: 3.568\n",
            "Model saved!\n",
            "Step    50 : 402.93 ms/batch | loss  3.07\n",
            "Step   100 : 349.23 ms/batch | loss  2.96\n",
            "Step   150 : 343.54 ms/batch | loss  2.98\n",
            "Step   200 : 346.84 ms/batch | loss  3.14\n",
            "Step   250 : 347.42 ms/batch | loss  3.16\n",
            "Step   300 : 340.46 ms/batch | loss  3.04\n",
            "Step   350 : 345.47 ms/batch | loss  3.02\n",
            "Step   400 : 343.56 ms/batch | loss  3.03\n",
            "Step   450 : 341.50 ms/batch | loss  2.99\n",
            "Step   500 : 345.22 ms/batch | loss  3.00\n",
            "Step   550 : 345.83 ms/batch | loss  3.37\n",
            "Step   600 : 341.27 ms/batch | loss  2.95\n",
            "Step   650 : 340.21 ms/batch | loss  3.07\n",
            "Step   700 : 344.01 ms/batch | loss  3.12\n",
            "Step   750 : 341.56 ms/batch | loss  2.95\n",
            "Step   800 : 349.09 ms/batch | loss  2.90\n",
            "Step   850 : 345.32 ms/batch | loss  3.07\n",
            "Step   900 : 345.12 ms/batch | loss  3.16\n",
            "Step   950 : 345.55 ms/batch | loss  3.17\n",
            "Step  1000 : 343.59 ms/batch | loss  3.11\n",
            "Step  1050 : 345.33 ms/batch | loss  3.00\n",
            "Step  1100 : 348.36 ms/batch | loss  2.97\n",
            "Step  1150 : 340.21 ms/batch | loss  3.05\n",
            "Step  1200 : 344.70 ms/batch | loss  3.20\n",
            "Step  1250 : 349.61 ms/batch | loss  3.25\n",
            "Step  1300 : 347.13 ms/batch | loss  3.14\n",
            "Step  1350 : 345.21 ms/batch | loss  2.34\n",
            "Step  1400 : 346.72 ms/batch | loss  3.00\n",
            "Step  1450 : 346.83 ms/batch | loss  2.49\n",
            "Step  1500 : 339.17 ms/batch | loss  2.81\n",
            "Step  1550 : 344.33 ms/batch | loss  3.16\n",
            "Step  1600 : 344.78 ms/batch | loss  3.26\n",
            "Step  1650 : 350.70 ms/batch | loss  3.25\n",
            "Step  1700 : 343.60 ms/batch | loss  2.87\n",
            "Step  1750 : 344.90 ms/batch | loss  3.20\n",
            "Step  1800 : 341.88 ms/batch | loss  3.29\n",
            "Step  1850 : 337.23 ms/batch | loss  3.13\n",
            "Step  1900 : 341.97 ms/batch | loss  3.21\n",
            "Step  1950 : 347.57 ms/batch | loss  3.22\n",
            "Step  2000 : 344.13 ms/batch | loss  2.76\n",
            "Step  2050 : 346.34 ms/batch | loss  3.00\n",
            "Step  2100 : 341.75 ms/batch | loss  3.16\n",
            "Step  2150 : 341.67 ms/batch | loss  2.42\n",
            "Step  2200 : 346.22 ms/batch | loss  3.19\n",
            "Step  2250 : 339.57 ms/batch | loss  3.13\n",
            "Step  2300 : 343.41 ms/batch | loss  2.97\n",
            "Step  2350 : 349.08 ms/batch | loss  3.11\n",
            "Step  2400 : 345.88 ms/batch | loss  3.08\n",
            "Step  2450 : 350.91 ms/batch | loss  2.99\n",
            "Step  2500 : 344.48 ms/batch | loss  3.19\n",
            "Step  2550 : 345.91 ms/batch | loss  3.01\n",
            "Step  2600 : 345.25 ms/batch | loss  3.11\n",
            "Step  2650 : 345.53 ms/batch | loss  3.08\n",
            "Step  2700 : 348.95 ms/batch | loss  3.10\n",
            "Step  2750 : 346.85 ms/batch | loss  3.01\n",
            "Step    50 : 312.87 ms/batch | loss  3.68\n",
            "Step   100 : 297.93 ms/batch | loss  3.61\n",
            "Step   150 : 300.44 ms/batch | loss  3.52\n",
            "Step   200 : 294.66 ms/batch | loss  3.54\n",
            "Step   250 : 295.98 ms/batch | loss  3.62\n",
            "Step   300 : 304.17 ms/batch | loss  3.85\n",
            "Step   350 : 294.69 ms/batch | loss  3.61\n",
            "Step   400 : 297.65 ms/batch | loss  3.64\n",
            "Step   450 : 295.49 ms/batch | loss  3.44\n",
            "Step   500 : 303.76 ms/batch | loss  3.42\n",
            "Step   550 : 303.51 ms/batch | loss  3.60\n",
            "Step   600 : 301.05 ms/batch | loss  3.70\n",
            "Epoch: 08\n",
            "\tTrain Loss: 3.099\n",
            "\t Val. Loss: 3.527\n",
            "Model saved!\n",
            "Step    50 : 402.78 ms/batch | loss  3.24\n",
            "Step   100 : 341.69 ms/batch | loss  2.99\n",
            "Step   150 : 341.44 ms/batch | loss  2.91\n",
            "Step   200 : 341.29 ms/batch | loss  3.12\n",
            "Step   250 : 346.49 ms/batch | loss  3.18\n",
            "Step   300 : 342.38 ms/batch | loss  3.18\n",
            "Step   350 : 341.56 ms/batch | loss  3.05\n",
            "Step   400 : 349.65 ms/batch | loss  3.06\n",
            "Step   450 : 344.73 ms/batch | loss  3.10\n",
            "Step   500 : 343.74 ms/batch | loss  3.37\n",
            "Step   550 : 347.60 ms/batch | loss  2.67\n",
            "Step   600 : 344.26 ms/batch | loss  3.25\n",
            "Step   650 : 346.44 ms/batch | loss  3.16\n",
            "Step   700 : 342.23 ms/batch | loss  3.07\n",
            "Step   750 : 341.49 ms/batch | loss  3.35\n",
            "Step   800 : 346.42 ms/batch | loss  2.96\n",
            "Step   850 : 347.35 ms/batch | loss  2.99\n",
            "Step   900 : 347.25 ms/batch | loss  3.13\n",
            "Step   950 : 341.62 ms/batch | loss  3.12\n",
            "Step  1000 : 347.19 ms/batch | loss  3.29\n",
            "Step  1050 : 344.92 ms/batch | loss  3.03\n",
            "Step  1100 : 345.61 ms/batch | loss  3.33\n",
            "Step  1150 : 341.83 ms/batch | loss  3.20\n",
            "Step  1200 : 345.22 ms/batch | loss  2.88\n",
            "Step  1250 : 341.26 ms/batch | loss  3.01\n",
            "Step  1300 : 340.18 ms/batch | loss  3.03\n",
            "Step  1350 : 344.04 ms/batch | loss  2.97\n",
            "Step  1400 : 343.73 ms/batch | loss  2.92\n",
            "Step  1450 : 344.69 ms/batch | loss  3.05\n",
            "Step  1500 : 340.11 ms/batch | loss  2.98\n",
            "Step  1550 : 342.60 ms/batch | loss  3.16\n",
            "Step  1600 : 345.06 ms/batch | loss  2.31\n",
            "Step  1650 : 348.61 ms/batch | loss  3.13\n",
            "Step  1700 : 342.73 ms/batch | loss  2.91\n",
            "Step  1750 : 340.04 ms/batch | loss  3.05\n",
            "Step  1800 : 346.26 ms/batch | loss  3.31\n",
            "Step  1850 : 348.18 ms/batch | loss  3.20\n",
            "Step  1900 : 347.57 ms/batch | loss  3.10\n",
            "Step  1950 : 344.47 ms/batch | loss  3.26\n",
            "Step  2000 : 348.00 ms/batch | loss  3.13\n",
            "Step  2050 : 345.70 ms/batch | loss  3.08\n",
            "Step  2100 : 349.08 ms/batch | loss  3.28\n",
            "Step  2150 : 347.16 ms/batch | loss  3.16\n",
            "Step  2200 : 345.80 ms/batch | loss  3.05\n",
            "Step  2250 : 340.83 ms/batch | loss  3.15\n",
            "Step  2300 : 350.57 ms/batch | loss  3.01\n",
            "Step  2350 : 343.00 ms/batch | loss  3.15\n",
            "Step  2400 : 341.93 ms/batch | loss  3.17\n",
            "Step  2450 : 345.53 ms/batch | loss  3.15\n",
            "Step  2500 : 349.26 ms/batch | loss  3.22\n",
            "Step  2550 : 345.97 ms/batch | loss  2.98\n",
            "Step  2600 : 345.54 ms/batch | loss  3.01\n",
            "Step  2650 : 345.27 ms/batch | loss  3.00\n",
            "Step  2700 : 344.25 ms/batch | loss  3.03\n",
            "Step  2750 : 349.12 ms/batch | loss  3.04\n",
            "Step    50 : 321.44 ms/batch | loss  3.58\n",
            "Step   100 : 294.75 ms/batch | loss  3.41\n",
            "Step   150 : 298.73 ms/batch | loss  2.97\n",
            "Step   200 : 297.99 ms/batch | loss  3.48\n",
            "Step   250 : 294.62 ms/batch | loss  3.48\n",
            "Step   300 : 302.38 ms/batch | loss  3.43\n",
            "Step   350 : 298.10 ms/batch | loss  3.44\n",
            "Step   400 : 295.48 ms/batch | loss  3.62\n",
            "Step   450 : 298.77 ms/batch | loss  3.54\n",
            "Step   500 : 304.25 ms/batch | loss  3.56\n",
            "Step   550 : 299.80 ms/batch | loss  3.56\n",
            "Step   600 : 298.05 ms/batch | loss  3.65\n",
            "Epoch: 09\n",
            "\tTrain Loss: 3.073\n",
            "\t Val. Loss: 3.448\n",
            "Model saved!\n",
            "Step    50 : 397.94 ms/batch | loss  3.13\n",
            "Step   100 : 346.08 ms/batch | loss  3.12\n",
            "Step   150 : 344.89 ms/batch | loss  3.21\n",
            "Step   200 : 351.11 ms/batch | loss  2.89\n",
            "Step   250 : 347.15 ms/batch | loss  3.07\n",
            "Step   300 : 341.88 ms/batch | loss  2.82\n",
            "Step   350 : 344.18 ms/batch | loss  3.16\n",
            "Step   400 : 343.46 ms/batch | loss  2.91\n",
            "Step   450 : 345.96 ms/batch | loss  3.25\n",
            "Step   500 : 343.83 ms/batch | loss  3.13\n",
            "Step   550 : 346.46 ms/batch | loss  2.98\n",
            "Step   600 : 350.01 ms/batch | loss  3.11\n",
            "Step   650 : 349.98 ms/batch | loss  3.02\n",
            "Step   700 : 345.05 ms/batch | loss  2.92\n",
            "Step   750 : 345.31 ms/batch | loss  2.88\n",
            "Step   800 : 347.47 ms/batch | loss  3.07\n",
            "Step   850 : 346.43 ms/batch | loss  3.27\n",
            "Step   900 : 343.85 ms/batch | loss  3.12\n",
            "Step   950 : 347.34 ms/batch | loss  3.04\n",
            "Step  1000 : 344.73 ms/batch | loss  3.21\n",
            "Step  1050 : 342.47 ms/batch | loss  3.27\n",
            "Step  1100 : 345.13 ms/batch | loss  3.19\n",
            "Step  1150 : 347.17 ms/batch | loss  2.78\n",
            "Step  1200 : 346.62 ms/batch | loss  3.07\n",
            "Step  1250 : 345.77 ms/batch | loss  3.07\n",
            "Step  1300 : 345.10 ms/batch | loss  3.25\n",
            "Step  1350 : 343.16 ms/batch | loss  3.08\n",
            "Step  1400 : 347.01 ms/batch | loss  3.10\n",
            "Step  1450 : 339.86 ms/batch | loss  3.20\n",
            "Step  1500 : 350.01 ms/batch | loss  3.07\n",
            "Step  1550 : 342.22 ms/batch | loss  2.98\n",
            "Step  1600 : 348.74 ms/batch | loss  3.19\n",
            "Step  1650 : 345.81 ms/batch | loss  3.11\n",
            "Step  1700 : 350.52 ms/batch | loss  3.10\n",
            "Step  1750 : 343.01 ms/batch | loss  3.04\n",
            "Step  1800 : 343.56 ms/batch | loss  2.90\n",
            "Step  1850 : 348.13 ms/batch | loss  3.06\n",
            "Step  1900 : 347.28 ms/batch | loss  2.84\n",
            "Step  1950 : 346.67 ms/batch | loss  3.17\n",
            "Step  2000 : 341.29 ms/batch | loss  2.86\n",
            "Step  2050 : 340.69 ms/batch | loss  3.01\n",
            "Step  2100 : 338.14 ms/batch | loss  3.21\n",
            "Step  2150 : 348.24 ms/batch | loss  3.06\n",
            "Step  2200 : 344.31 ms/batch | loss  2.94\n",
            "Step  2250 : 341.10 ms/batch | loss  3.07\n",
            "Step  2300 : 342.09 ms/batch | loss  3.02\n",
            "Step  2350 : 340.89 ms/batch | loss  3.30\n",
            "Step  2400 : 344.47 ms/batch | loss  3.12\n",
            "Step  2450 : 345.87 ms/batch | loss  3.21\n",
            "Step  2500 : 343.91 ms/batch | loss  3.10\n",
            "Step  2550 : 342.42 ms/batch | loss  3.15\n",
            "Step  2600 : 344.88 ms/batch | loss  3.15\n",
            "Step  2650 : 342.05 ms/batch | loss  3.04\n",
            "Step  2700 : 338.69 ms/batch | loss  3.24\n",
            "Step  2750 : 345.35 ms/batch | loss  2.95\n",
            "Step    50 : 314.48 ms/batch | loss  3.57\n",
            "Step   100 : 302.36 ms/batch | loss  3.41\n",
            "Step   150 : 296.53 ms/batch | loss  3.12\n",
            "Step   200 : 297.85 ms/batch | loss  3.73\n",
            "Step   250 : 295.37 ms/batch | loss  3.41\n",
            "Step   300 : 299.20 ms/batch | loss  3.73\n",
            "Step   350 : 305.29 ms/batch | loss  3.77\n",
            "Step   400 : 293.83 ms/batch | loss  3.47\n",
            "Step   450 : 298.93 ms/batch | loss  3.50\n",
            "Step   500 : 300.23 ms/batch | loss  3.71\n",
            "Step   550 : 300.16 ms/batch | loss  3.47\n",
            "Step   600 : 298.96 ms/batch | loss  3.62\n",
            "Epoch: 10\n",
            "\tTrain Loss: 3.050\n",
            "\t Val. Loss: 3.452\n",
            "Model saved!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}